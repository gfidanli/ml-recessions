{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "cpi = pd.read_csv(\"resources/cpi_final.csv\")\n",
    "gdp = pd.read_csv(\"resources/gdp_final.csv\")\n",
    "gdp_pct = pd.read_csv(\"resources/gdp_pct_chg_final.csv\")\n",
    "houst = pd.read_csv(\"resources/housing_starts_final.csv\")\n",
    "opg = pd.read_csv(\"resources/output_gap_final.csv\")\n",
    "rec_dt = pd.read_csv(\"resources/recession_dates_final.csv\")\n",
    "unrate = pd.read_csv(\"resources/unemployment_rate_final.csv\")\n",
    "fed_funds = pd.read_csv(\"resources/fed_funds_final.csv\")\n",
    "yield10_2 = pd.read_csv(\"resources/10YT_minus_2YT_final.csv\")\n",
    "fred = pd.read_csv(\"resources/FRED_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data sets into one data frame\n",
    "dfs = [cpi, gdp, gdp_pct, houst, opg, rec_dt, unrate, fed_funds, yield10_2, fred]\n",
    "df = reduce(lambda left,right: pd.merge(left,right,on=['quarter'],how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data frame by quarter\n",
    "df = df.sort_values(by=['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date columns\n",
    "df = df.drop(columns=['date_x','date_y'])\n",
    "\n",
    "# Rename target column\n",
    "df = df.rename(columns={'target':'recession_actual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to quarter\n",
    "df = df.set_index('quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_consumer_price_index</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdp_pct_change</th>\n",
       "      <th>avg_housing_starts</th>\n",
       "      <th>output_gap</th>\n",
       "      <th>avg_unemployment_rate</th>\n",
       "      <th>fed_funds_avg_rate</th>\n",
       "      <th>fed_funds_percent_change_prev_quarter</th>\n",
       "      <th>fed_funds_st_dev_rate</th>\n",
       "      <th>10YT_minus_2YT_avg</th>\n",
       "      <th>10YT_minus_2YT_percent_change_prev_quarter</th>\n",
       "      <th>real_disp_pers_inc</th>\n",
       "      <th>personal_consumption_exp_excl_food_energy</th>\n",
       "      <th>cpi_US_total</th>\n",
       "      <th>tot_public_debt_as_pct_of_gdp</th>\n",
       "      <th>gross_private_domestic_invest</th>\n",
       "      <th>M2_velocity</th>\n",
       "      <th>median_sls_price_houses_sold_US</th>\n",
       "      <th>nat_rate_of_unemp_long_term</th>\n",
       "      <th>personal_consumption_expenditures</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019Q1</th>\n",
       "      <td>253.311333</td>\n",
       "      <td>21098.827</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>0.848147</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2.401311</td>\n",
       "      <td>0.083088</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>-0.271429</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.644936</td>\n",
       "      <td>104.40334</td>\n",
       "      <td>3783.364</td>\n",
       "      <td>1.458</td>\n",
       "      <td>313000.0</td>\n",
       "      <td>4.577</td>\n",
       "      <td>14266.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019Q2</th>\n",
       "      <td>255.139333</td>\n",
       "      <td>21340.267</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1255.666667</td>\n",
       "      <td>0.828815</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.397813</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.811376</td>\n",
       "      <td>103.20060</td>\n",
       "      <td>3749.471</td>\n",
       "      <td>1.457</td>\n",
       "      <td>322500.0</td>\n",
       "      <td>4.572</td>\n",
       "      <td>14511.176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_consumer_price_index        gdp  gdp_pct_change  \\\n",
       "quarter                                                        \n",
       "2019Q1                 253.311333  21098.827             3.9   \n",
       "2019Q2                 255.139333  21340.267             4.7   \n",
       "\n",
       "         avg_housing_starts  output_gap  avg_unemployment_rate  \\\n",
       "quarter                                                          \n",
       "2019Q1          1213.000000    0.848147               4.133333   \n",
       "2019Q2          1255.666667    0.828815               3.500000   \n",
       "\n",
       "         fed_funds_avg_rate  fed_funds_percent_change_prev_quarter  \\\n",
       "quarter                                                              \n",
       "2019Q1             2.401311                               0.083088   \n",
       "2019Q2             2.397813                              -0.001457   \n",
       "\n",
       "         fed_funds_st_dev_rate  10YT_minus_2YT_avg  \\\n",
       "quarter                                              \n",
       "2019Q1                0.004646            0.170000   \n",
       "2019Q2                0.024002            0.213333   \n",
       "\n",
       "         10YT_minus_2YT_percent_change_prev_quarter  real_disp_pers_inc  \\\n",
       "quarter                                                                   \n",
       "2019Q1                                    -0.271429                 4.5   \n",
       "2019Q2                                     0.254902                 2.4   \n",
       "\n",
       "         personal_consumption_exp_excl_food_energy  cpi_US_total  \\\n",
       "quarter                                                            \n",
       "2019Q1                                         1.6      1.644936   \n",
       "2019Q2                                         1.6      1.811376   \n",
       "\n",
       "         tot_public_debt_as_pct_of_gdp  gross_private_domestic_invest  \\\n",
       "quarter                                                                 \n",
       "2019Q1                       104.40334                       3783.364   \n",
       "2019Q2                       103.20060                       3749.471   \n",
       "\n",
       "         M2_velocity  median_sls_price_houses_sold_US  \\\n",
       "quarter                                                 \n",
       "2019Q1         1.458                         313000.0   \n",
       "2019Q2         1.457                         322500.0   \n",
       "\n",
       "         nat_rate_of_unemp_long_term  personal_consumption_expenditures  \n",
       "quarter                                                                  \n",
       "2019Q1                         4.577                          14266.250  \n",
       "2019Q2                         4.572                          14511.176  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save 2019 Q1 & Q2\n",
    "df_2019 = df.iloc[[-4,-3],:]\n",
    "df_2019 = df_2019.drop(columns=['recession_actual'])\n",
    "df_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_consumer_price_index</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdp_pct_change</th>\n",
       "      <th>avg_housing_starts</th>\n",
       "      <th>output_gap</th>\n",
       "      <th>recession_actual</th>\n",
       "      <th>avg_unemployment_rate</th>\n",
       "      <th>fed_funds_avg_rate</th>\n",
       "      <th>fed_funds_percent_change_prev_quarter</th>\n",
       "      <th>fed_funds_st_dev_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>10YT_minus_2YT_percent_change_prev_quarter</th>\n",
       "      <th>real_disp_pers_inc</th>\n",
       "      <th>personal_consumption_exp_excl_food_energy</th>\n",
       "      <th>cpi_US_total</th>\n",
       "      <th>tot_public_debt_as_pct_of_gdp</th>\n",
       "      <th>gross_private_domestic_invest</th>\n",
       "      <th>M2_velocity</th>\n",
       "      <th>median_sls_price_houses_sold_US</th>\n",
       "      <th>nat_rate_of_unemp_long_term</th>\n",
       "      <th>personal_consumption_expenditures</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018Q1</th>\n",
       "      <td>249.250333</td>\n",
       "      <td>20163.159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1320.666667</td>\n",
       "      <td>0.202456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.448966</td>\n",
       "      <td>0.204683</td>\n",
       "      <td>0.083902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113861</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.214194</td>\n",
       "      <td>104.59493</td>\n",
       "      <td>3542.412</td>\n",
       "      <td>1.451</td>\n",
       "      <td>331800.0</td>\n",
       "      <td>4.597</td>\n",
       "      <td>13728.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018Q2</th>\n",
       "      <td>250.578667</td>\n",
       "      <td>20510.177</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1259.666667</td>\n",
       "      <td>0.589182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.727176</td>\n",
       "      <td>0.192007</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251397</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.711887</td>\n",
       "      <td>103.33928</td>\n",
       "      <td>3561.592</td>\n",
       "      <td>1.461</td>\n",
       "      <td>315600.0</td>\n",
       "      <td>4.592</td>\n",
       "      <td>13939.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018Q3</th>\n",
       "      <td>251.828667</td>\n",
       "      <td>20749.752</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1233.000000</td>\n",
       "      <td>0.821959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>1.923492</td>\n",
       "      <td>0.113663</td>\n",
       "      <td>0.047184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432836</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.640940</td>\n",
       "      <td>103.69309</td>\n",
       "      <td>3683.981</td>\n",
       "      <td>1.462</td>\n",
       "      <td>330900.0</td>\n",
       "      <td>4.587</td>\n",
       "      <td>14114.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018Q4</th>\n",
       "      <td>252.759000</td>\n",
       "      <td>20897.804</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1185.000000</td>\n",
       "      <td>0.592021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>2.217097</td>\n",
       "      <td>0.152641</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.203131</td>\n",
       "      <td>105.15026</td>\n",
       "      <td>3725.234</td>\n",
       "      <td>1.462</td>\n",
       "      <td>322800.0</td>\n",
       "      <td>4.582</td>\n",
       "      <td>14211.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019Q1</th>\n",
       "      <td>253.311333</td>\n",
       "      <td>21098.827</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>0.848147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2.401311</td>\n",
       "      <td>0.083088</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271429</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.644936</td>\n",
       "      <td>104.40334</td>\n",
       "      <td>3783.364</td>\n",
       "      <td>1.458</td>\n",
       "      <td>313000.0</td>\n",
       "      <td>4.577</td>\n",
       "      <td>14266.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_consumer_price_index        gdp  gdp_pct_change  \\\n",
       "quarter                                                        \n",
       "2018Q1                 249.250333  20163.159             5.0   \n",
       "2018Q2                 250.578667  20510.177             7.1   \n",
       "2018Q3                 251.828667  20749.752             4.8   \n",
       "2018Q4                 252.759000  20897.804             2.9   \n",
       "2019Q1                 253.311333  21098.827             3.9   \n",
       "\n",
       "         avg_housing_starts  output_gap  recession_actual  \\\n",
       "quarter                                                     \n",
       "2018Q1          1320.666667    0.202456               0.0   \n",
       "2018Q2          1259.666667    0.589182               0.0   \n",
       "2018Q3          1233.000000    0.821959               0.0   \n",
       "2018Q4          1185.000000    0.592021               0.0   \n",
       "2019Q1          1213.000000    0.848147               0.0   \n",
       "\n",
       "         avg_unemployment_rate  fed_funds_avg_rate  \\\n",
       "quarter                                              \n",
       "2018Q1                4.333333            1.448966   \n",
       "2018Q2                3.833333            1.727176   \n",
       "2018Q3                3.866667            1.923492   \n",
       "2018Q4                3.566667            2.217097   \n",
       "2019Q1                4.133333            2.401311   \n",
       "\n",
       "         fed_funds_percent_change_prev_quarter  fed_funds_st_dev_rate  ...  \\\n",
       "quarter                                                                ...   \n",
       "2018Q1                                0.204683               0.083902  ...   \n",
       "2018Q2                                0.192007               0.075492  ...   \n",
       "2018Q3                                0.113663               0.047184  ...   \n",
       "2018Q4                                0.152641               0.066218  ...   \n",
       "2019Q1                                0.083088               0.004646  ...   \n",
       "\n",
       "         10YT_minus_2YT_percent_change_prev_quarter  real_disp_pers_inc  \\\n",
       "quarter                                                                   \n",
       "2018Q1                                    -0.113861                 6.9   \n",
       "2018Q2                                    -0.251397                 2.7   \n",
       "2018Q3                                    -0.432836                 3.3   \n",
       "2018Q4                                    -0.078947                 2.8   \n",
       "2019Q1                                    -0.271429                 4.5   \n",
       "\n",
       "         personal_consumption_exp_excl_food_energy  cpi_US_total  \\\n",
       "quarter                                                            \n",
       "2018Q1                                         1.8      2.214194   \n",
       "2018Q2                                         2.0      2.711887   \n",
       "2018Q3                                         2.0      2.640940   \n",
       "2018Q4                                         1.9      2.203131   \n",
       "2019Q1                                         1.6      1.644936   \n",
       "\n",
       "         tot_public_debt_as_pct_of_gdp  gross_private_domestic_invest  \\\n",
       "quarter                                                                 \n",
       "2018Q1                       104.59493                       3542.412   \n",
       "2018Q2                       103.33928                       3561.592   \n",
       "2018Q3                       103.69309                       3683.981   \n",
       "2018Q4                       105.15026                       3725.234   \n",
       "2019Q1                       104.40334                       3783.364   \n",
       "\n",
       "         M2_velocity  median_sls_price_houses_sold_US  \\\n",
       "quarter                                                 \n",
       "2018Q1         1.451                         331800.0   \n",
       "2018Q2         1.461                         315600.0   \n",
       "2018Q3         1.462                         330900.0   \n",
       "2018Q4         1.462                         322800.0   \n",
       "2019Q1         1.458                         313000.0   \n",
       "\n",
       "         nat_rate_of_unemp_long_term  personal_consumption_expenditures  \n",
       "quarter                                                                  \n",
       "2018Q1                         4.597                          13728.357  \n",
       "2018Q2                         4.592                          13939.828  \n",
       "2018Q3                         4.587                          14114.559  \n",
       "2018Q4                         4.582                          14211.920  \n",
       "2019Q1                         4.577                          14266.250  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift data with sliding window technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recession_1q_out'] = df['recession_actual'].shift(-1)\n",
    "df['recession_2q_out'] = df['recession_actual'].shift(-2)\n",
    "df['recession_4q_out'] = df['recession_actual'].shift(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three datasets -- 1 for each model (recession 1Qtr out, 2Qtrs out, 4Qtrs out)\n",
    "df_q1 = df.drop(columns=['recession_2q_out','recession_4q_out','recession_actual'])\n",
    "df_q2 = df.drop(columns=['recession_4q_out','recession_1q_out','recession_actual'])\n",
    "df_q4 = df.drop(columns=['recession_1q_out','recession_2q_out','recession_actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values\n",
    "df_q1 = df_q1.dropna()\n",
    "df_q2 = df_q2.dropna()\n",
    "df_q4 = df_q4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y1 = df_q1['recession_1q_out']\n",
    "y2 = df_q2['recession_2q_out']\n",
    "y3 = df_q4['recession_4q_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target\n",
    "df_q1 = df_q1.drop(columns=['recession_1q_out'])\n",
    "df_q2 = df_q2.drop(columns=['recession_2q_out'])\n",
    "df_q4 = df_q4.drop(columns=['recession_4q_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X\n",
    "X_q1 = df_q1\n",
    "X_q2 = df_q2\n",
    "X_q4 = df_q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing (stratify=None, shuffle=False)\n",
    "X1_train, X1_test, y1_train, y1_test=train_test_split(X_q1, y1, train_size=0.8, random_state=42, shuffle=False)\n",
    "X2_train, X2_test, y2_train, y2_test=train_test_split(X_q2, y2, train_size=0.8, random_state=42, shuffle=False)\n",
    "X3_train, X3_test, y3_train, y3_test=train_test_split(X_q4, y3, train_size=0.8, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create scaler object\n",
    "X1_scaler = StandardScaler().fit(X1_train)\n",
    "X2_scaler = StandardScaler().fit(X2_train)\n",
    "X3_scaler = StandardScaler().fit(X3_train)\n",
    "\n",
    "# X full scaler\n",
    "X1_full_scaler = StandardScaler().fit(X_q1)\n",
    "X2_full_scaler = StandardScaler().fit(X_q2)\n",
    "X3_full_scaler = StandardScaler().fit(X_q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale training data\n",
    "X1_train_scaled = X1_scaler.transform(X1_train)\n",
    "X2_train_scaled = X2_scaler.transform(X2_train)\n",
    "X3_train_scaled = X3_scaler.transform(X3_train)\n",
    "\n",
    "# Scale testing data\n",
    "X1_test_scaled = X1_scaler.transform(X1_test)\n",
    "X2_test_scaled = X2_scaler.transform(X2_test)\n",
    "X3_test_scaled = X3_scaler.transform(X3_test)\n",
    "\n",
    "# Scale full X data (no splits)\n",
    "X1_full_scaled = X1_full_scaler.transform(X_q1)\n",
    "X2_full_scaled = X2_full_scaler.transform(X_q2)\n",
    "X3_full_scaled = X3_full_scaler.transform(X_q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data to fit LSTM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to reshape data\n",
    "def reshape_data(obj):\n",
    "    reshaped_obj = np.reshape(obj, (obj.shape[0], obj.shape[1], 1))\n",
    "    return reshaped_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training data\n",
    "reshaped_X1_train_scaled = reshape_data(X1_train_scaled)\n",
    "reshaped_X2_train_scaled = reshape_data(X2_train_scaled)\n",
    "reshaped_X3_train_scaled = reshape_data(X3_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape testing data\n",
    "reshaped_X1_test_scaled = reshape_data(X1_test_scaled)\n",
    "reshaped_X2_test_scaled = reshape_data(X2_test_scaled)\n",
    "reshaped_X3_test_scaled = reshape_data(X3_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_full\n",
    "reshaped_X1_full = reshape_data(X1_full_scaled)\n",
    "reshaped_X2_full = reshape_data(X2_full_scaled)\n",
    "reshaped_X3_full = reshape_data(X3_full_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Add layers\n",
    "model.add(LSTM(128, input_shape=(reshaped_X1_train_scaled.shape[1],1), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())  # Normalize activation outputs\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and predict on X1-Y1 data (recession 1 quarter out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 28 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "108/108 - 14s - loss: 1.1660 - acc: 0.4352 - val_loss: 0.6789 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "108/108 - 2s - loss: 0.7579 - acc: 0.5926 - val_loss: 0.6666 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "108/108 - 2s - loss: 0.7314 - acc: 0.7130 - val_loss: 0.6542 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "108/108 - 3s - loss: 0.7282 - acc: 0.6759 - val_loss: 0.6385 - val_acc: 0.7500\n",
      "Epoch 5/100\n",
      "108/108 - 4s - loss: 0.6127 - acc: 0.7037 - val_loss: 0.6208 - val_acc: 0.7500\n",
      "Epoch 6/100\n",
      "108/108 - 2s - loss: 0.5618 - acc: 0.7778 - val_loss: 0.6052 - val_acc: 0.7500\n",
      "Epoch 7/100\n",
      "108/108 - 2s - loss: 0.5914 - acc: 0.7685 - val_loss: 0.5900 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      "108/108 - 3s - loss: 0.5128 - acc: 0.7870 - val_loss: 0.5736 - val_acc: 0.7500\n",
      "Epoch 9/100\n",
      "108/108 - 2s - loss: 0.5991 - acc: 0.7593 - val_loss: 0.5659 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      "108/108 - 2s - loss: 0.5630 - acc: 0.7407 - val_loss: 0.5584 - val_acc: 0.7500\n",
      "Epoch 11/100\n",
      "108/108 - 2s - loss: 0.6034 - acc: 0.7407 - val_loss: 0.5526 - val_acc: 0.7500\n",
      "Epoch 12/100\n",
      "108/108 - 2s - loss: 0.5406 - acc: 0.7407 - val_loss: 0.5433 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "108/108 - 2s - loss: 0.4674 - acc: 0.7593 - val_loss: 0.5377 - val_acc: 0.7500\n",
      "Epoch 14/100\n",
      "108/108 - 2s - loss: 0.5165 - acc: 0.7778 - val_loss: 0.5361 - val_acc: 0.7500\n",
      "Epoch 15/100\n",
      "108/108 - 2s - loss: 0.4867 - acc: 0.8148 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 16/100\n",
      "108/108 - 2s - loss: 0.4638 - acc: 0.7685 - val_loss: 0.5265 - val_acc: 0.7500\n",
      "Epoch 17/100\n",
      "108/108 - 2s - loss: 0.5590 - acc: 0.7685 - val_loss: 0.5214 - val_acc: 0.7500\n",
      "Epoch 18/100\n",
      "108/108 - 2s - loss: 0.5151 - acc: 0.7407 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 19/100\n",
      "108/108 - 2s - loss: 0.4732 - acc: 0.8056 - val_loss: 0.5152 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      "108/108 - 2s - loss: 0.4386 - acc: 0.7963 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      "108/108 - 2s - loss: 0.3219 - acc: 0.8241 - val_loss: 0.5228 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "108/108 - 2s - loss: 0.3870 - acc: 0.8519 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      "108/108 - 2s - loss: 0.3829 - acc: 0.8333 - val_loss: 0.5433 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      "108/108 - 2s - loss: 0.4647 - acc: 0.7685 - val_loss: 0.5596 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "108/108 - 2s - loss: 0.4810 - acc: 0.8241 - val_loss: 0.5777 - val_acc: 0.7500\n",
      "Epoch 26/100\n",
      "108/108 - 2s - loss: 0.3118 - acc: 0.8704 - val_loss: 0.5875 - val_acc: 0.7500\n",
      "Epoch 27/100\n",
      "108/108 - 2s - loss: 0.4480 - acc: 0.7963 - val_loss: 0.5798 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "108/108 - 2s - loss: 0.4880 - acc: 0.7037 - val_loss: 0.5698 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "108/108 - 2s - loss: 0.2876 - acc: 0.8704 - val_loss: 0.5513 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      "108/108 - 2s - loss: 0.3612 - acc: 0.8056 - val_loss: 0.5403 - val_acc: 0.7500\n",
      "Epoch 31/100\n",
      "108/108 - 1s - loss: 0.4344 - acc: 0.8056 - val_loss: 0.5300 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "108/108 - 1s - loss: 0.3812 - acc: 0.8241 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 33/100\n",
      "108/108 - 2s - loss: 0.3665 - acc: 0.8519 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "108/108 - 2s - loss: 0.4026 - acc: 0.8519 - val_loss: 0.5293 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "108/108 - 2s - loss: 0.3824 - acc: 0.7963 - val_loss: 0.5432 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      "108/108 - 2s - loss: 0.2930 - acc: 0.8611 - val_loss: 0.5756 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      "108/108 - 2s - loss: 0.3572 - acc: 0.8333 - val_loss: 0.6127 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "108/108 - 2s - loss: 0.3779 - acc: 0.7685 - val_loss: 0.6441 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "108/108 - 2s - loss: 0.3333 - acc: 0.8426 - val_loss: 0.6543 - val_acc: 0.7500\n",
      "Epoch 40/100\n",
      "108/108 - 2s - loss: 0.3735 - acc: 0.8241 - val_loss: 0.6222 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "108/108 - 2s - loss: 0.3625 - acc: 0.7778 - val_loss: 0.5827 - val_acc: 0.7500\n",
      "Epoch 42/100\n",
      "108/108 - 2s - loss: 0.2835 - acc: 0.8796 - val_loss: 0.5768 - val_acc: 0.7500\n",
      "Epoch 43/100\n",
      "108/108 - 2s - loss: 0.3620 - acc: 0.8333 - val_loss: 0.5793 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      "108/108 - 2s - loss: 0.3737 - acc: 0.8611 - val_loss: 0.5961 - val_acc: 0.7500\n",
      "Epoch 45/100\n",
      "108/108 - 2s - loss: 0.3145 - acc: 0.8426 - val_loss: 0.6013 - val_acc: 0.7500\n",
      "Epoch 46/100\n",
      "108/108 - 2s - loss: 0.2905 - acc: 0.8704 - val_loss: 0.6094 - val_acc: 0.7143\n",
      "Epoch 47/100\n",
      "108/108 - 2s - loss: 0.2577 - acc: 0.9167 - val_loss: 0.5843 - val_acc: 0.6429\n",
      "Epoch 48/100\n",
      "108/108 - 2s - loss: 0.2860 - acc: 0.8796 - val_loss: 0.5502 - val_acc: 0.6786\n",
      "Epoch 49/100\n",
      "108/108 - 2s - loss: 0.2805 - acc: 0.8519 - val_loss: 0.5486 - val_acc: 0.6786\n",
      "Epoch 50/100\n",
      "108/108 - 2s - loss: 0.3405 - acc: 0.8611 - val_loss: 0.5713 - val_acc: 0.6786\n",
      "Epoch 51/100\n",
      "108/108 - 2s - loss: 0.2814 - acc: 0.8889 - val_loss: 0.6623 - val_acc: 0.7143\n",
      "Epoch 52/100\n",
      "108/108 - 2s - loss: 0.3054 - acc: 0.8148 - val_loss: 0.8006 - val_acc: 0.3214\n",
      "Epoch 53/100\n",
      "108/108 - 2s - loss: 0.2380 - acc: 0.8704 - val_loss: 0.9253 - val_acc: 0.2143\n",
      "Epoch 54/100\n",
      "108/108 - 2s - loss: 0.2357 - acc: 0.9074 - val_loss: 0.9446 - val_acc: 0.2143\n",
      "Epoch 55/100\n",
      "108/108 - 2s - loss: 0.2767 - acc: 0.8611 - val_loss: 0.9064 - val_acc: 0.2143\n",
      "Epoch 56/100\n",
      "108/108 - 2s - loss: 0.1863 - acc: 0.9352 - val_loss: 0.9332 - val_acc: 0.2143\n",
      "Epoch 57/100\n",
      "108/108 - 2s - loss: 0.2443 - acc: 0.9352 - val_loss: 0.9500 - val_acc: 0.2500\n",
      "Epoch 58/100\n",
      "108/108 - 2s - loss: 0.2067 - acc: 0.9074 - val_loss: 0.9492 - val_acc: 0.2857\n",
      "Epoch 59/100\n",
      "108/108 - 2s - loss: 0.2622 - acc: 0.8611 - val_loss: 0.9753 - val_acc: 0.2500\n",
      "Epoch 60/100\n",
      "108/108 - 2s - loss: 0.2125 - acc: 0.9074 - val_loss: 0.9533 - val_acc: 0.2857\n",
      "Epoch 61/100\n",
      "108/108 - 2s - loss: 0.2017 - acc: 0.9352 - val_loss: 0.8595 - val_acc: 0.3571\n",
      "Epoch 62/100\n",
      "108/108 - 2s - loss: 0.2290 - acc: 0.8796 - val_loss: 0.8028 - val_acc: 0.4286\n",
      "Epoch 63/100\n",
      "108/108 - 2s - loss: 0.2086 - acc: 0.9074 - val_loss: 0.8067 - val_acc: 0.3929\n",
      "Epoch 64/100\n",
      "108/108 - 2s - loss: 0.1613 - acc: 0.9444 - val_loss: 0.8682 - val_acc: 0.4286\n",
      "Epoch 65/100\n",
      "108/108 - 2s - loss: 0.2471 - acc: 0.8519 - val_loss: 1.0368 - val_acc: 0.2857\n",
      "Epoch 66/100\n",
      "108/108 - 2s - loss: 0.2358 - acc: 0.8796 - val_loss: 1.1895 - val_acc: 0.1786\n",
      "Epoch 67/100\n",
      "108/108 - 2s - loss: 0.2139 - acc: 0.9259 - val_loss: 1.2248 - val_acc: 0.1786\n",
      "Epoch 68/100\n",
      "108/108 - 2s - loss: 0.1988 - acc: 0.9074 - val_loss: 1.1341 - val_acc: 0.2143\n",
      "Epoch 69/100\n",
      "108/108 - 2s - loss: 0.1639 - acc: 0.9259 - val_loss: 1.0504 - val_acc: 0.2857\n",
      "Epoch 70/100\n",
      "108/108 - 2s - loss: 0.1474 - acc: 0.9537 - val_loss: 0.9963 - val_acc: 0.3571\n",
      "Epoch 71/100\n",
      "108/108 - 2s - loss: 0.2216 - acc: 0.8889 - val_loss: 0.9319 - val_acc: 0.4643\n",
      "Epoch 72/100\n",
      "108/108 - 2s - loss: 0.1292 - acc: 0.9352 - val_loss: 0.8657 - val_acc: 0.5357\n",
      "Epoch 73/100\n",
      "108/108 - 3s - loss: 0.1649 - acc: 0.9167 - val_loss: 0.9643 - val_acc: 0.5357\n",
      "Epoch 74/100\n",
      "108/108 - 2s - loss: 0.1745 - acc: 0.9167 - val_loss: 0.9941 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "108/108 - 2s - loss: 0.1605 - acc: 0.9167 - val_loss: 0.9971 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "108/108 - 3s - loss: 0.1579 - acc: 0.9352 - val_loss: 0.9945 - val_acc: 0.5714\n",
      "Epoch 77/100\n",
      "108/108 - 2s - loss: 0.1364 - acc: 0.9722 - val_loss: 1.0173 - val_acc: 0.5714\n",
      "Epoch 78/100\n",
      "108/108 - 2s - loss: 0.1535 - acc: 0.9167 - val_loss: 1.0101 - val_acc: 0.5714\n",
      "Epoch 79/100\n",
      "108/108 - 2s - loss: 0.0805 - acc: 0.9907 - val_loss: 1.0115 - val_acc: 0.5714\n",
      "Epoch 80/100\n",
      "108/108 - 2s - loss: 0.1775 - acc: 0.9074 - val_loss: 1.0345 - val_acc: 0.5714\n",
      "Epoch 81/100\n",
      "108/108 - 2s - loss: 0.1703 - acc: 0.9074 - val_loss: 1.0851 - val_acc: 0.5714\n",
      "Epoch 82/100\n",
      "108/108 - 2s - loss: 0.1718 - acc: 0.9259 - val_loss: 1.1578 - val_acc: 0.5357\n",
      "Epoch 83/100\n",
      "108/108 - 2s - loss: 0.1639 - acc: 0.9352 - val_loss: 1.2417 - val_acc: 0.4286\n",
      "Epoch 84/100\n",
      "108/108 - 2s - loss: 0.1175 - acc: 0.9537 - val_loss: 1.1954 - val_acc: 0.3571\n",
      "Epoch 85/100\n",
      "108/108 - 2s - loss: 0.2194 - acc: 0.9259 - val_loss: 1.2438 - val_acc: 0.3929\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 2s - loss: 0.1298 - acc: 0.9630 - val_loss: 1.2563 - val_acc: 0.4643\n",
      "Epoch 87/100\n",
      "108/108 - 2s - loss: 0.1275 - acc: 0.9444 - val_loss: 1.1990 - val_acc: 0.5357\n",
      "Epoch 88/100\n",
      "108/108 - 2s - loss: 0.1238 - acc: 0.9537 - val_loss: 1.1152 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "108/108 - 2s - loss: 0.1597 - acc: 0.9259 - val_loss: 1.1447 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "108/108 - 2s - loss: 0.1263 - acc: 0.9630 - val_loss: 1.2465 - val_acc: 0.3929\n",
      "Epoch 91/100\n",
      "108/108 - 2s - loss: 0.0986 - acc: 0.9722 - val_loss: 1.3762 - val_acc: 0.3929\n",
      "Epoch 92/100\n",
      "108/108 - 2s - loss: 0.1101 - acc: 0.9630 - val_loss: 1.3460 - val_acc: 0.4286\n",
      "Epoch 93/100\n",
      "108/108 - 2s - loss: 0.1352 - acc: 0.9352 - val_loss: 1.2818 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "108/108 - 2s - loss: 0.1274 - acc: 0.9537 - val_loss: 1.1500 - val_acc: 0.4643\n",
      "Epoch 95/100\n",
      "108/108 - 2s - loss: 0.0923 - acc: 0.9722 - val_loss: 0.9608 - val_acc: 0.5357\n",
      "Epoch 96/100\n",
      "108/108 - 2s - loss: 0.1110 - acc: 0.9537 - val_loss: 0.9213 - val_acc: 0.5357\n",
      "Epoch 97/100\n",
      "108/108 - 2s - loss: 0.0696 - acc: 0.9815 - val_loss: 0.9897 - val_acc: 0.5357\n",
      "Epoch 98/100\n",
      "108/108 - 2s - loss: 0.0866 - acc: 0.9722 - val_loss: 1.1319 - val_acc: 0.4643\n",
      "Epoch 99/100\n",
      "108/108 - 2s - loss: 0.1037 - acc: 0.9444 - val_loss: 1.1942 - val_acc: 0.4643\n",
      "Epoch 100/100\n",
      "108/108 - 2s - loss: 0.1076 - acc: 0.9537 - val_loss: 1.2345 - val_acc: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4becdb38>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X1_train_scaled, y1_train, validation_split=0.2, epochs=100, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.2604 - acc: 0.9412\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss1, model_accuracy1 = model.evaluate(reshaped_X1_test_scaled, y1_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions1 = model.predict_classes(reshaped_X1_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "one_qtr_out = pd.DataFrame({\"Predicted\":predictions1, \"Actual\":y1_test})\n",
    "# one_qtr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X1-Y1 data (recession 1 quarter out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  2]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X1 model\n",
    "con_mat = confusion_matrix(y1_test, predictions1)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97        34\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.50      0.47      0.48        34\n",
      "weighted avg       1.00      0.94      0.97        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y1_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name1 = f\"unshuffled-1q-out-{dt.datetime.now()}\"\n",
    "model.save(f\"models/{name1}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale 2019 data \n",
    "scaled_X1_2019 = X1_scaler.transform(df_2019)\n",
    "\n",
    "# Reshape 2019 data\n",
    "reshaped_X1_2019 = reshape_data(scaled_X1_2019)\n",
    "\n",
    "# Predict on 2019\n",
    "pred_X1_2019 = model.predict_classes(reshaped_X1_2019)\n",
    "pred_X1_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X1_full = model.predict_classes(reshaped_X1_full)\n",
    "\n",
    "# Preview results\n",
    "X1_full_results = pd.DataFrame({\"Predicted\":pred_X1_full, \"Actual\":y1})\n",
    "# X1_full_results.loc[X1_full_results[\"Actual\"]==1]\n",
    "\n",
    "# Export results for graphing\n",
    "X1_full_results.to_csv(f\"resources/predictions/X1_NS_VS20_{dt.datetime.now()}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and predict on X2-Y2 data (recession 2 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 - 2s - loss: 0.3953 - acc: 0.8889 - val_loss: 1.3952 - val_acc: 0.4074\n",
      "Epoch 2/100\n",
      "108/108 - 2s - loss: 0.2284 - acc: 0.9167 - val_loss: 1.1751 - val_acc: 0.4815\n",
      "Epoch 3/100\n",
      "108/108 - 2s - loss: 0.2066 - acc: 0.8889 - val_loss: 1.0892 - val_acc: 0.4815\n",
      "Epoch 4/100\n",
      "108/108 - 2s - loss: 0.1426 - acc: 0.9259 - val_loss: 1.2940 - val_acc: 0.5556\n",
      "Epoch 5/100\n",
      "108/108 - 2s - loss: 0.2345 - acc: 0.8981 - val_loss: 1.3114 - val_acc: 0.4815\n",
      "Epoch 6/100\n",
      "108/108 - 2s - loss: 0.1833 - acc: 0.9167 - val_loss: 1.2332 - val_acc: 0.4815\n",
      "Epoch 7/100\n",
      "108/108 - 2s - loss: 0.1619 - acc: 0.9259 - val_loss: 1.2021 - val_acc: 0.5556\n",
      "Epoch 8/100\n",
      "108/108 - 2s - loss: 0.1788 - acc: 0.9259 - val_loss: 1.1035 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "108/108 - 2s - loss: 0.1108 - acc: 0.9537 - val_loss: 1.0505 - val_acc: 0.5926\n",
      "Epoch 10/100\n",
      "108/108 - 2s - loss: 0.1446 - acc: 0.9537 - val_loss: 1.1043 - val_acc: 0.5556\n",
      "Epoch 11/100\n",
      "108/108 - 2s - loss: 0.1593 - acc: 0.9074 - val_loss: 1.2595 - val_acc: 0.4074\n",
      "Epoch 12/100\n",
      "108/108 - 2s - loss: 0.1264 - acc: 0.9352 - val_loss: 1.2979 - val_acc: 0.4074\n",
      "Epoch 13/100\n",
      "108/108 - 2s - loss: 0.1033 - acc: 0.9444 - val_loss: 1.2714 - val_acc: 0.3704\n",
      "Epoch 14/100\n",
      "108/108 - 2s - loss: 0.0961 - acc: 0.9630 - val_loss: 1.2517 - val_acc: 0.4444\n",
      "Epoch 15/100\n",
      "108/108 - 2s - loss: 0.0883 - acc: 0.9815 - val_loss: 1.2569 - val_acc: 0.4444\n",
      "Epoch 16/100\n",
      "108/108 - 2s - loss: 0.0783 - acc: 0.9815 - val_loss: 1.2464 - val_acc: 0.4815\n",
      "Epoch 17/100\n",
      "108/108 - 2s - loss: 0.1294 - acc: 0.9630 - val_loss: 1.2989 - val_acc: 0.4815\n",
      "Epoch 18/100\n",
      "108/108 - 2s - loss: 0.1018 - acc: 0.9630 - val_loss: 1.2230 - val_acc: 0.5185\n",
      "Epoch 19/100\n",
      "108/108 - 2s - loss: 0.1154 - acc: 0.9444 - val_loss: 1.2529 - val_acc: 0.4815\n",
      "Epoch 20/100\n",
      "108/108 - 2s - loss: 0.0994 - acc: 0.9537 - val_loss: 1.4302 - val_acc: 0.3704\n",
      "Epoch 21/100\n",
      "108/108 - 2s - loss: 0.0904 - acc: 0.9722 - val_loss: 1.5006 - val_acc: 0.3704\n",
      "Epoch 22/100\n",
      "108/108 - 2s - loss: 0.0973 - acc: 0.9630 - val_loss: 1.5776 - val_acc: 0.3333\n",
      "Epoch 23/100\n",
      "108/108 - 2s - loss: 0.0808 - acc: 0.9722 - val_loss: 1.5696 - val_acc: 0.2963\n",
      "Epoch 24/100\n",
      "108/108 - 2s - loss: 0.0962 - acc: 0.9444 - val_loss: 1.5016 - val_acc: 0.3333\n",
      "Epoch 25/100\n",
      "108/108 - 2s - loss: 0.0817 - acc: 0.9722 - val_loss: 1.4260 - val_acc: 0.5185\n",
      "Epoch 26/100\n",
      "108/108 - 2s - loss: 0.0631 - acc: 0.9907 - val_loss: 1.3749 - val_acc: 0.5556\n",
      "Epoch 27/100\n",
      "108/108 - 2s - loss: 0.0775 - acc: 0.9815 - val_loss: 1.3773 - val_acc: 0.5556\n",
      "Epoch 28/100\n",
      "108/108 - 2s - loss: 0.1284 - acc: 0.9259 - val_loss: 1.4651 - val_acc: 0.5556\n",
      "Epoch 29/100\n",
      "108/108 - 2s - loss: 0.0998 - acc: 0.9537 - val_loss: 1.5857 - val_acc: 0.4074\n",
      "Epoch 30/100\n",
      "108/108 - 2s - loss: 0.0773 - acc: 0.9722 - val_loss: 1.7013 - val_acc: 0.4444\n",
      "Epoch 31/100\n",
      "108/108 - 2s - loss: 0.0873 - acc: 0.9815 - val_loss: 1.7303 - val_acc: 0.4815\n",
      "Epoch 32/100\n",
      "108/108 - 2s - loss: 0.0543 - acc: 0.9815 - val_loss: 1.7351 - val_acc: 0.4815\n",
      "Epoch 33/100\n",
      "108/108 - 2s - loss: 0.0657 - acc: 0.9815 - val_loss: 1.7189 - val_acc: 0.4444\n",
      "Epoch 34/100\n",
      "108/108 - 2s - loss: 0.0409 - acc: 1.0000 - val_loss: 1.6977 - val_acc: 0.5185\n",
      "Epoch 35/100\n",
      "108/108 - 2s - loss: 0.0445 - acc: 0.9722 - val_loss: 1.7473 - val_acc: 0.5556\n",
      "Epoch 36/100\n",
      "108/108 - 2s - loss: 0.0798 - acc: 0.9444 - val_loss: 1.8873 - val_acc: 0.5926\n",
      "Epoch 37/100\n",
      "108/108 - 2s - loss: 0.0843 - acc: 0.9630 - val_loss: 1.8091 - val_acc: 0.6667\n",
      "Epoch 38/100\n",
      "108/108 - 2s - loss: 0.1031 - acc: 0.9444 - val_loss: 1.6482 - val_acc: 0.6296\n",
      "Epoch 39/100\n",
      "108/108 - 2s - loss: 0.0466 - acc: 0.9815 - val_loss: 1.5691 - val_acc: 0.5185\n",
      "Epoch 40/100\n",
      "108/108 - 2s - loss: 0.0788 - acc: 0.9630 - val_loss: 1.6318 - val_acc: 0.5556\n",
      "Epoch 41/100\n",
      "108/108 - 2s - loss: 0.0603 - acc: 0.9722 - val_loss: 1.8055 - val_acc: 0.4444\n",
      "Epoch 42/100\n",
      "108/108 - 2s - loss: 0.0537 - acc: 0.9815 - val_loss: 1.8413 - val_acc: 0.4074\n",
      "Epoch 43/100\n",
      "108/108 - 2s - loss: 0.0562 - acc: 0.9815 - val_loss: 1.7775 - val_acc: 0.4074\n",
      "Epoch 44/100\n",
      "108/108 - 2s - loss: 0.0457 - acc: 0.9907 - val_loss: 1.7662 - val_acc: 0.4074\n",
      "Epoch 45/100\n",
      "108/108 - 2s - loss: 0.0559 - acc: 0.9907 - val_loss: 1.6792 - val_acc: 0.4444\n",
      "Epoch 46/100\n",
      "108/108 - 2s - loss: 0.0456 - acc: 0.9907 - val_loss: 1.6100 - val_acc: 0.4444\n",
      "Epoch 47/100\n",
      "108/108 - 2s - loss: 0.0570 - acc: 0.9815 - val_loss: 1.5681 - val_acc: 0.5185\n",
      "Epoch 48/100\n",
      "108/108 - 2s - loss: 0.0546 - acc: 0.9815 - val_loss: 1.5789 - val_acc: 0.5185\n",
      "Epoch 49/100\n",
      "108/108 - 2s - loss: 0.0291 - acc: 1.0000 - val_loss: 1.6439 - val_acc: 0.4444\n",
      "Epoch 50/100\n",
      "108/108 - 2s - loss: 0.0315 - acc: 0.9907 - val_loss: 1.6948 - val_acc: 0.4444\n",
      "Epoch 51/100\n",
      "108/108 - 2s - loss: 0.0807 - acc: 0.9722 - val_loss: 1.7940 - val_acc: 0.4074\n",
      "Epoch 52/100\n",
      "108/108 - 2s - loss: 0.0527 - acc: 0.9907 - val_loss: 1.8047 - val_acc: 0.4074\n",
      "Epoch 53/100\n",
      "108/108 - 2s - loss: 0.1076 - acc: 0.9630 - val_loss: 1.5999 - val_acc: 0.3704\n",
      "Epoch 54/100\n",
      "108/108 - 2s - loss: 0.0588 - acc: 0.9722 - val_loss: 1.6760 - val_acc: 0.4815\n",
      "Epoch 55/100\n",
      "108/108 - 2s - loss: 0.0636 - acc: 0.9722 - val_loss: 1.6245 - val_acc: 0.5185\n",
      "Epoch 56/100\n",
      "108/108 - 2s - loss: 0.0546 - acc: 0.9722 - val_loss: 1.5592 - val_acc: 0.5556\n",
      "Epoch 57/100\n",
      "108/108 - 2s - loss: 0.0400 - acc: 0.9722 - val_loss: 1.4761 - val_acc: 0.5556\n",
      "Epoch 58/100\n",
      "108/108 - 2s - loss: 0.0647 - acc: 0.9630 - val_loss: 1.4817 - val_acc: 0.5556\n",
      "Epoch 59/100\n",
      "108/108 - 2s - loss: 0.0361 - acc: 0.9815 - val_loss: 1.5054 - val_acc: 0.5185\n",
      "Epoch 60/100\n",
      "108/108 - 2s - loss: 0.0375 - acc: 0.9907 - val_loss: 1.5924 - val_acc: 0.4815\n",
      "Epoch 61/100\n",
      "108/108 - 2s - loss: 0.0404 - acc: 0.9907 - val_loss: 1.6598 - val_acc: 0.4815\n",
      "Epoch 62/100\n",
      "108/108 - 2s - loss: 0.0400 - acc: 0.9907 - val_loss: 1.7196 - val_acc: 0.4074\n",
      "Epoch 63/100\n",
      "108/108 - 2s - loss: 0.0291 - acc: 0.9907 - val_loss: 1.7584 - val_acc: 0.4444\n",
      "Epoch 64/100\n",
      "108/108 - 2s - loss: 0.0531 - acc: 0.9815 - val_loss: 1.8346 - val_acc: 0.4815\n",
      "Epoch 65/100\n",
      "108/108 - 2s - loss: 0.0201 - acc: 1.0000 - val_loss: 1.8804 - val_acc: 0.4815\n",
      "Epoch 66/100\n",
      "108/108 - 2s - loss: 0.0239 - acc: 0.9907 - val_loss: 1.9303 - val_acc: 0.4074\n",
      "Epoch 67/100\n",
      "108/108 - 2s - loss: 0.0231 - acc: 1.0000 - val_loss: 1.9523 - val_acc: 0.4074\n",
      "Epoch 68/100\n",
      "108/108 - 2s - loss: 0.0133 - acc: 1.0000 - val_loss: 1.9609 - val_acc: 0.4074\n",
      "Epoch 69/100\n",
      "108/108 - 2s - loss: 0.0378 - acc: 0.9815 - val_loss: 1.9480 - val_acc: 0.3704\n",
      "Epoch 70/100\n",
      "108/108 - 2s - loss: 0.0295 - acc: 0.9815 - val_loss: 1.9894 - val_acc: 0.3333\n",
      "Epoch 71/100\n",
      "108/108 - 2s - loss: 0.0325 - acc: 0.9907 - val_loss: 2.0433 - val_acc: 0.2963\n",
      "Epoch 72/100\n",
      "108/108 - 2s - loss: 0.0317 - acc: 0.9907 - val_loss: 2.0459 - val_acc: 0.3333\n",
      "Epoch 73/100\n",
      "108/108 - 2s - loss: 0.0139 - acc: 1.0000 - val_loss: 1.9392 - val_acc: 0.4074\n",
      "Epoch 74/100\n",
      "108/108 - 2s - loss: 0.0296 - acc: 0.9907 - val_loss: 1.8590 - val_acc: 0.4444\n",
      "Epoch 75/100\n",
      "108/108 - 2s - loss: 0.0443 - acc: 0.9907 - val_loss: 1.7672 - val_acc: 0.4815\n",
      "Epoch 76/100\n",
      "108/108 - 2s - loss: 0.0368 - acc: 0.9815 - val_loss: 1.7446 - val_acc: 0.4444\n",
      "Epoch 77/100\n",
      "108/108 - 2s - loss: 0.0123 - acc: 1.0000 - val_loss: 1.7609 - val_acc: 0.4444\n",
      "Epoch 78/100\n",
      "108/108 - 2s - loss: 0.0316 - acc: 0.9907 - val_loss: 1.7745 - val_acc: 0.4444\n",
      "Epoch 79/100\n",
      "108/108 - 2s - loss: 0.0152 - acc: 1.0000 - val_loss: 1.8782 - val_acc: 0.3333\n",
      "Epoch 80/100\n",
      "108/108 - 2s - loss: 0.0162 - acc: 1.0000 - val_loss: 1.8996 - val_acc: 0.3333\n",
      "Epoch 81/100\n",
      "108/108 - 2s - loss: 0.0090 - acc: 1.0000 - val_loss: 1.8830 - val_acc: 0.3333\n",
      "Epoch 82/100\n",
      "108/108 - 2s - loss: 0.0298 - acc: 0.9907 - val_loss: 2.0023 - val_acc: 0.3333\n",
      "Epoch 83/100\n",
      "108/108 - 2s - loss: 0.0180 - acc: 1.0000 - val_loss: 2.1754 - val_acc: 0.2963\n",
      "Epoch 84/100\n",
      "108/108 - 2s - loss: 0.0163 - acc: 1.0000 - val_loss: 2.2896 - val_acc: 0.3704\n",
      "Epoch 85/100\n",
      "108/108 - 2s - loss: 0.0622 - acc: 0.9815 - val_loss: 2.3081 - val_acc: 0.3333\n",
      "Epoch 86/100\n",
      "108/108 - 2s - loss: 0.0378 - acc: 0.9907 - val_loss: 2.2566 - val_acc: 0.3333\n",
      "Epoch 87/100\n",
      "108/108 - 2s - loss: 0.0230 - acc: 1.0000 - val_loss: 2.3186 - val_acc: 0.3704\n",
      "Epoch 88/100\n",
      "108/108 - 2s - loss: 0.0126 - acc: 1.0000 - val_loss: 2.3660 - val_acc: 0.3333\n",
      "Epoch 89/100\n",
      "108/108 - 2s - loss: 0.0480 - acc: 0.9722 - val_loss: 2.3018 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "108/108 - 2s - loss: 0.0093 - acc: 1.0000 - val_loss: 2.1848 - val_acc: 0.4074\n",
      "Epoch 91/100\n",
      "108/108 - 2s - loss: 0.0126 - acc: 1.0000 - val_loss: 2.1704 - val_acc: 0.4074\n",
      "Epoch 92/100\n",
      "108/108 - 2s - loss: 0.0094 - acc: 1.0000 - val_loss: 2.1731 - val_acc: 0.3704\n",
      "Epoch 93/100\n",
      "108/108 - 2s - loss: 0.0347 - acc: 0.9907 - val_loss: 2.3487 - val_acc: 0.2963\n",
      "Epoch 94/100\n",
      "108/108 - 2s - loss: 0.0129 - acc: 1.0000 - val_loss: 2.3371 - val_acc: 0.3333\n",
      "Epoch 95/100\n",
      "108/108 - 2s - loss: 0.0248 - acc: 0.9907 - val_loss: 2.2191 - val_acc: 0.3333\n",
      "Epoch 96/100\n",
      "108/108 - 2s - loss: 0.0062 - acc: 1.0000 - val_loss: 2.1653 - val_acc: 0.2963\n",
      "Epoch 97/100\n",
      "108/108 - 2s - loss: 0.0221 - acc: 1.0000 - val_loss: 2.1844 - val_acc: 0.3704\n",
      "Epoch 98/100\n",
      "108/108 - 2s - loss: 0.0077 - acc: 1.0000 - val_loss: 2.2262 - val_acc: 0.4074\n",
      "Epoch 99/100\n",
      "108/108 - 2s - loss: 0.0149 - acc: 1.0000 - val_loss: 2.2758 - val_acc: 0.4074\n",
      "Epoch 100/100\n",
      "108/108 - 2s - loss: 0.0270 - acc: 0.9907 - val_loss: 2.3517 - val_acc: 0.2963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4bf61e80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X2_train_scaled, y2_train, validation_split=0.2, epochs=100, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 1.4541 - acc: 0.3529\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss2, model_accuracy2 = model.evaluate(reshaped_X2_test_scaled, y2_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions2 = model.predict_classes(reshaped_X2_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "two_qtrs_out = pd.DataFrame({\"Predicted\":predictions2, \"Actual\":y2_test})\n",
    "# two_qtrs_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X2-Y2 data (recession 2 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 22]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X2 model\n",
    "con_mat = confusion_matrix(y2_test, predictions2)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.35      0.52        34\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35        34\n",
      "   macro avg       0.50      0.18      0.26        34\n",
      "weighted avg       1.00      0.35      0.52        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y2_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name2 = f\"unshuffled-2q-out-{dt.datetime.now()}\"\n",
    "model.save(f\"models/{name2}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale 2019 data \n",
    "scaled_X2_2019 = X2_scaler.transform(df_2019)\n",
    "\n",
    "# Reshape 2019 data\n",
    "reshaped_X2_2019 = reshape_data(scaled_X2_2019)\n",
    "\n",
    "# Predict on 2019\n",
    "pred_X2_2019 = model.predict_classes(reshaped_X2_2019)\n",
    "pred_X2_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X2_full = model.predict_classes(reshaped_X2_full)\n",
    "\n",
    "# Preview results\n",
    "X2_full_results = pd.DataFrame({\"Predicted\":pred_X2_full, \"Actual\":y2})\n",
    "# X2_full_results.loc[X2_full_results[\"Actual\"]==1]\n",
    "\n",
    "# Export results for graphing\n",
    "X2_full_results.to_csv(f\"resources/predictions/X2_NS_VS20_{dt.datetime.now()}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X3-Y3 data (recession 4 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "106/106 - 2s - loss: 1.0183 - acc: 0.8396 - val_loss: 1.5934 - val_acc: 0.4815\n",
      "Epoch 2/100\n",
      "106/106 - 2s - loss: 0.8284 - acc: 0.8491 - val_loss: 1.6719 - val_acc: 0.4444\n",
      "Epoch 3/100\n",
      "106/106 - 2s - loss: 0.5277 - acc: 0.8491 - val_loss: 1.6116 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "106/106 - 2s - loss: 0.2606 - acc: 0.8868 - val_loss: 1.3125 - val_acc: 0.3333\n",
      "Epoch 5/100\n",
      "106/106 - 2s - loss: 0.2087 - acc: 0.8868 - val_loss: 0.9745 - val_acc: 0.4815\n",
      "Epoch 6/100\n",
      "106/106 - 2s - loss: 0.2595 - acc: 0.8491 - val_loss: 1.0309 - val_acc: 0.4074\n",
      "Epoch 7/100\n",
      "106/106 - 2s - loss: 0.1843 - acc: 0.9057 - val_loss: 1.2620 - val_acc: 0.4815\n",
      "Epoch 8/100\n",
      "106/106 - 2s - loss: 0.1797 - acc: 0.9434 - val_loss: 1.2898 - val_acc: 0.4444\n",
      "Epoch 9/100\n",
      "106/106 - 2s - loss: 0.1622 - acc: 0.9434 - val_loss: 1.3142 - val_acc: 0.4444\n",
      "Epoch 10/100\n",
      "106/106 - 2s - loss: 0.1039 - acc: 0.9528 - val_loss: 1.5165 - val_acc: 0.4444\n",
      "Epoch 11/100\n",
      "106/106 - 2s - loss: 0.1333 - acc: 0.9434 - val_loss: 1.7203 - val_acc: 0.4815\n",
      "Epoch 12/100\n",
      "106/106 - 2s - loss: 0.1131 - acc: 0.9434 - val_loss: 1.7455 - val_acc: 0.4815\n",
      "Epoch 13/100\n",
      "106/106 - 2s - loss: 0.1383 - acc: 0.9434 - val_loss: 1.6582 - val_acc: 0.4815\n",
      "Epoch 14/100\n",
      "106/106 - 2s - loss: 0.1035 - acc: 0.9528 - val_loss: 1.5610 - val_acc: 0.4444\n",
      "Epoch 15/100\n",
      "106/106 - 2s - loss: 0.0736 - acc: 0.9811 - val_loss: 1.6258 - val_acc: 0.4444\n",
      "Epoch 16/100\n",
      "106/106 - 2s - loss: 0.1113 - acc: 0.9340 - val_loss: 1.9334 - val_acc: 0.4444\n",
      "Epoch 17/100\n",
      "106/106 - 2s - loss: 0.1098 - acc: 0.9623 - val_loss: 1.8831 - val_acc: 0.4074\n",
      "Epoch 18/100\n",
      "106/106 - 2s - loss: 0.0710 - acc: 0.9811 - val_loss: 1.6597 - val_acc: 0.4444\n",
      "Epoch 19/100\n",
      "106/106 - 2s - loss: 0.0532 - acc: 0.9811 - val_loss: 1.6915 - val_acc: 0.4444\n",
      "Epoch 20/100\n",
      "106/106 - 2s - loss: 0.0665 - acc: 0.9811 - val_loss: 1.6647 - val_acc: 0.4815\n",
      "Epoch 21/100\n",
      "106/106 - 2s - loss: 0.0857 - acc: 0.9623 - val_loss: 1.7986 - val_acc: 0.4815\n",
      "Epoch 22/100\n",
      "106/106 - 2s - loss: 0.0652 - acc: 0.9717 - val_loss: 2.0898 - val_acc: 0.4074\n",
      "Epoch 23/100\n",
      "106/106 - 2s - loss: 0.1110 - acc: 0.9434 - val_loss: 2.5819 - val_acc: 0.5185\n",
      "Epoch 24/100\n",
      "106/106 - 2s - loss: 0.0787 - acc: 0.9623 - val_loss: 2.7820 - val_acc: 0.5185\n",
      "Epoch 25/100\n",
      "106/106 - 2s - loss: 0.0828 - acc: 0.9528 - val_loss: 2.8660 - val_acc: 0.5185\n",
      "Epoch 26/100\n",
      "106/106 - 2s - loss: 0.0636 - acc: 0.9811 - val_loss: 2.9025 - val_acc: 0.5185\n",
      "Epoch 27/100\n",
      "106/106 - 2s - loss: 0.0655 - acc: 0.9623 - val_loss: 2.7862 - val_acc: 0.4074\n",
      "Epoch 28/100\n",
      "106/106 - 2s - loss: 0.0612 - acc: 0.9717 - val_loss: 2.8378 - val_acc: 0.3704\n",
      "Epoch 29/100\n",
      "106/106 - 2s - loss: 0.0576 - acc: 0.9811 - val_loss: 2.8576 - val_acc: 0.4074\n",
      "Epoch 30/100\n",
      "106/106 - 2s - loss: 0.0411 - acc: 0.9811 - val_loss: 2.9726 - val_acc: 0.3704\n",
      "Epoch 31/100\n",
      "106/106 - 2s - loss: 0.0353 - acc: 0.9906 - val_loss: 3.1090 - val_acc: 0.4074\n",
      "Epoch 32/100\n",
      "106/106 - 2s - loss: 0.0354 - acc: 0.9906 - val_loss: 3.1880 - val_acc: 0.4074\n",
      "Epoch 33/100\n",
      "106/106 - 2s - loss: 0.0979 - acc: 0.9811 - val_loss: 3.0933 - val_acc: 0.4074\n",
      "Epoch 34/100\n",
      "106/106 - 2s - loss: 0.0447 - acc: 0.9717 - val_loss: 3.0047 - val_acc: 0.4815\n",
      "Epoch 35/100\n",
      "106/106 - 2s - loss: 0.0980 - acc: 0.9717 - val_loss: 3.0920 - val_acc: 0.4815\n",
      "Epoch 36/100\n",
      "106/106 - 2s - loss: 0.0380 - acc: 0.9811 - val_loss: 3.1170 - val_acc: 0.4815\n",
      "Epoch 37/100\n",
      "106/106 - 2s - loss: 0.0131 - acc: 1.0000 - val_loss: 2.9239 - val_acc: 0.4444\n",
      "Epoch 38/100\n",
      "106/106 - 2s - loss: 0.0351 - acc: 0.9906 - val_loss: 2.6731 - val_acc: 0.4815\n",
      "Epoch 39/100\n",
      "106/106 - 2s - loss: 0.0607 - acc: 0.9811 - val_loss: 2.5775 - val_acc: 0.5185\n",
      "Epoch 40/100\n",
      "106/106 - 2s - loss: 0.0375 - acc: 0.9906 - val_loss: 2.6029 - val_acc: 0.5556\n",
      "Epoch 41/100\n",
      "106/106 - 2s - loss: 0.0286 - acc: 0.9906 - val_loss: 2.8718 - val_acc: 0.5556\n",
      "Epoch 42/100\n",
      "106/106 - 2s - loss: 0.0279 - acc: 0.9906 - val_loss: 3.2548 - val_acc: 0.5185\n",
      "Epoch 43/100\n",
      "106/106 - 2s - loss: 0.0672 - acc: 0.9717 - val_loss: 3.3723 - val_acc: 0.5185\n",
      "Epoch 44/100\n",
      "106/106 - 2s - loss: 0.0450 - acc: 0.9906 - val_loss: 3.2858 - val_acc: 0.5556\n",
      "Epoch 45/100\n",
      "106/106 - 2s - loss: 0.0268 - acc: 0.9906 - val_loss: 3.0608 - val_acc: 0.5926\n",
      "Epoch 46/100\n",
      "106/106 - 2s - loss: 0.0227 - acc: 0.9906 - val_loss: 3.0052 - val_acc: 0.5926\n",
      "Epoch 47/100\n",
      "106/106 - 2s - loss: 0.0234 - acc: 0.9906 - val_loss: 3.0103 - val_acc: 0.6296\n",
      "Epoch 48/100\n",
      "106/106 - 2s - loss: 0.0085 - acc: 1.0000 - val_loss: 3.0415 - val_acc: 0.6667\n",
      "Epoch 49/100\n",
      "106/106 - 2s - loss: 0.0232 - acc: 0.9906 - val_loss: 3.0975 - val_acc: 0.5926\n",
      "Epoch 50/100\n",
      "106/106 - 2s - loss: 0.0175 - acc: 0.9906 - val_loss: 3.2125 - val_acc: 0.6296\n",
      "Epoch 51/100\n",
      "106/106 - 2s - loss: 0.0098 - acc: 1.0000 - val_loss: 3.4177 - val_acc: 0.5556\n",
      "Epoch 52/100\n",
      "106/106 - 2s - loss: 0.0148 - acc: 1.0000 - val_loss: 3.7249 - val_acc: 0.4815\n",
      "Epoch 53/100\n",
      "106/106 - 2s - loss: 0.0458 - acc: 0.9906 - val_loss: 3.7962 - val_acc: 0.4444\n",
      "Epoch 54/100\n",
      "106/106 - 2s - loss: 0.0506 - acc: 0.9811 - val_loss: 3.6612 - val_acc: 0.4444\n",
      "Epoch 55/100\n",
      "106/106 - 2s - loss: 0.0242 - acc: 1.0000 - val_loss: 3.3866 - val_acc: 0.5185\n",
      "Epoch 56/100\n",
      "106/106 - 2s - loss: 0.0217 - acc: 0.9906 - val_loss: 3.2469 - val_acc: 0.5556\n",
      "Epoch 57/100\n",
      "106/106 - 2s - loss: 0.0141 - acc: 1.0000 - val_loss: 3.1971 - val_acc: 0.6296\n",
      "Epoch 58/100\n",
      "106/106 - 2s - loss: 0.0261 - acc: 0.9906 - val_loss: 3.3569 - val_acc: 0.5926\n",
      "Epoch 59/100\n",
      "106/106 - 2s - loss: 0.0245 - acc: 0.9906 - val_loss: 3.7124 - val_acc: 0.5185\n",
      "Epoch 60/100\n",
      "106/106 - 2s - loss: 0.0102 - acc: 1.0000 - val_loss: 3.8311 - val_acc: 0.4815\n",
      "Epoch 61/100\n",
      "106/106 - 2s - loss: 0.0114 - acc: 1.0000 - val_loss: 3.7967 - val_acc: 0.5556\n",
      "Epoch 62/100\n",
      "106/106 - 2s - loss: 0.0247 - acc: 0.9906 - val_loss: 3.7379 - val_acc: 0.5556\n",
      "Epoch 63/100\n",
      "106/106 - 2s - loss: 0.0472 - acc: 0.9811 - val_loss: 3.6756 - val_acc: 0.5185\n",
      "Epoch 64/100\n",
      "106/106 - 2s - loss: 0.0109 - acc: 1.0000 - val_loss: 3.8560 - val_acc: 0.4815\n",
      "Epoch 65/100\n",
      "106/106 - 2s - loss: 0.0081 - acc: 1.0000 - val_loss: 4.0024 - val_acc: 0.4815\n",
      "Epoch 66/100\n",
      "106/106 - 2s - loss: 0.0145 - acc: 0.9906 - val_loss: 4.1501 - val_acc: 0.4444\n",
      "Epoch 67/100\n",
      "106/106 - 2s - loss: 0.0141 - acc: 1.0000 - val_loss: 4.1919 - val_acc: 0.4444\n",
      "Epoch 68/100\n",
      "106/106 - 2s - loss: 0.0106 - acc: 1.0000 - val_loss: 4.2828 - val_acc: 0.4815\n",
      "Epoch 69/100\n",
      "106/106 - 2s - loss: 0.0074 - acc: 1.0000 - val_loss: 4.3627 - val_acc: 0.4815\n",
      "Epoch 70/100\n",
      "106/106 - 2s - loss: 0.0150 - acc: 0.9906 - val_loss: 4.4397 - val_acc: 0.4815\n",
      "Epoch 71/100\n",
      "106/106 - 2s - loss: 0.0152 - acc: 0.9906 - val_loss: 4.4186 - val_acc: 0.4444\n",
      "Epoch 72/100\n",
      "106/106 - 2s - loss: 0.0067 - acc: 1.0000 - val_loss: 4.3759 - val_acc: 0.4444\n",
      "Epoch 73/100\n",
      "106/106 - 2s - loss: 0.0132 - acc: 1.0000 - val_loss: 4.3581 - val_acc: 0.4444\n",
      "Epoch 74/100\n",
      "106/106 - 2s - loss: 0.0056 - acc: 1.0000 - val_loss: 4.2950 - val_acc: 0.4444\n",
      "Epoch 75/100\n",
      "106/106 - 2s - loss: 0.0142 - acc: 0.9906 - val_loss: 4.0419 - val_acc: 0.5185\n",
      "Epoch 76/100\n",
      "106/106 - 2s - loss: 0.0126 - acc: 0.9906 - val_loss: 4.3172 - val_acc: 0.4444\n",
      "Epoch 77/100\n",
      "106/106 - 2s - loss: 0.0025 - acc: 1.0000 - val_loss: 4.5213 - val_acc: 0.4444\n",
      "Epoch 78/100\n",
      "106/106 - 2s - loss: 0.0033 - acc: 1.0000 - val_loss: 4.6274 - val_acc: 0.4444\n",
      "Epoch 79/100\n",
      "106/106 - 2s - loss: 0.0069 - acc: 1.0000 - val_loss: 4.7338 - val_acc: 0.4074\n",
      "Epoch 80/100\n",
      "106/106 - 2s - loss: 0.0052 - acc: 1.0000 - val_loss: 4.8773 - val_acc: 0.4444\n",
      "Epoch 81/100\n",
      "106/106 - 2s - loss: 0.0163 - acc: 0.9906 - val_loss: 4.5843 - val_acc: 0.4444\n",
      "Epoch 82/100\n",
      "106/106 - 2s - loss: 0.0136 - acc: 1.0000 - val_loss: 4.3465 - val_acc: 0.4815\n",
      "Epoch 83/100\n",
      "106/106 - 2s - loss: 0.0059 - acc: 1.0000 - val_loss: 4.0818 - val_acc: 0.4815\n",
      "Epoch 84/100\n",
      "106/106 - 2s - loss: 0.0357 - acc: 0.9906 - val_loss: 3.6290 - val_acc: 0.6296\n",
      "Epoch 85/100\n",
      "106/106 - 2s - loss: 0.0125 - acc: 1.0000 - val_loss: 3.5131 - val_acc: 0.6667\n",
      "Epoch 86/100\n",
      "106/106 - 2s - loss: 0.0845 - acc: 0.9717 - val_loss: 3.4436 - val_acc: 0.5926\n",
      "Epoch 87/100\n",
      "106/106 - 2s - loss: 0.2254 - acc: 0.9811 - val_loss: 3.4931 - val_acc: 0.5556\n",
      "Epoch 88/100\n",
      "106/106 - 2s - loss: 0.0696 - acc: 0.9906 - val_loss: 3.4857 - val_acc: 0.4444\n",
      "Epoch 89/100\n",
      "106/106 - 2s - loss: 0.1005 - acc: 0.9528 - val_loss: 3.6140 - val_acc: 0.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "106/106 - 2s - loss: 0.0748 - acc: 0.9717 - val_loss: 2.8415 - val_acc: 0.5556\n",
      "Epoch 91/100\n",
      "106/106 - 2s - loss: 0.0535 - acc: 0.9717 - val_loss: 2.4422 - val_acc: 0.5926\n",
      "Epoch 92/100\n",
      "106/106 - 2s - loss: 0.0257 - acc: 0.9906 - val_loss: 2.2409 - val_acc: 0.5926\n",
      "Epoch 93/100\n",
      "106/106 - 2s - loss: 0.0943 - acc: 0.9717 - val_loss: 2.8140 - val_acc: 0.5926\n",
      "Epoch 94/100\n",
      "106/106 - 2s - loss: 0.0585 - acc: 0.9811 - val_loss: 4.4151 - val_acc: 0.4074\n",
      "Epoch 95/100\n",
      "106/106 - 2s - loss: 0.0644 - acc: 0.9811 - val_loss: 4.6664 - val_acc: 0.4074\n",
      "Epoch 96/100\n",
      "106/106 - 2s - loss: 0.0472 - acc: 0.9811 - val_loss: 4.4385 - val_acc: 0.4074\n",
      "Epoch 97/100\n",
      "106/106 - 2s - loss: 0.0310 - acc: 0.9906 - val_loss: 4.0606 - val_acc: 0.4444\n",
      "Epoch 98/100\n",
      "106/106 - 2s - loss: 0.0120 - acc: 0.9906 - val_loss: 3.6932 - val_acc: 0.4074\n",
      "Epoch 99/100\n",
      "106/106 - 2s - loss: 0.0135 - acc: 1.0000 - val_loss: 3.4333 - val_acc: 0.4444\n",
      "Epoch 100/100\n",
      "106/106 - 2s - loss: 0.0231 - acc: 1.0000 - val_loss: 3.3576 - val_acc: 0.4815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4c0960f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X3_train_scaled, y3_train, validation_split=0.2, epochs=100, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 2.7273 - acc: 0.5294\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss3, model_accuracy3 = model.evaluate(reshaped_X3_test_scaled, y3_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions3 = model.predict_classes(reshaped_X3_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "four_qtrs_out = pd.DataFrame({\"Predicted\":predictions3, \"Actual\":y3_test})\n",
    "# four_qtrs_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X3-Y3 data (recession 4 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 16]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X3 model\n",
    "con_mat = confusion_matrix(y3_test, predictions3)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.53      0.69        34\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        34\n",
      "   macro avg       0.50      0.26      0.35        34\n",
      "weighted avg       1.00      0.53      0.69        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y3_test, predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name3 = f\"unshuffled-4q-out-{dt.datetime.now()}\"\n",
    "model.save(f\"models/{name3}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale 2019 data \n",
    "scaled_X2_2019 = X2_scaler.transform(df_2019)\n",
    "\n",
    "# Reshape 2019 data\n",
    "reshaped_X2_2019 = reshape_data(scaled_X2_2019)\n",
    "\n",
    "# Predict on 2019\n",
    "pred_X2_2019 = model.predict_classes(reshaped_X2_2019)\n",
    "pred_X2_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X3_full = model.predict_classes(reshaped_X3_full)\n",
    "\n",
    "# Preview results\n",
    "X3_full_results = pd.DataFrame({\"Predicted\":pred_X3_full, \"Actual\":y3})\n",
    "# X3_full_results.loc[X3_full_results[\"Actual\"]==1]\n",
    "\n",
    "# Export results for graphing\n",
    "X3_full_results.to_csv(f\"resources/predictions/X3_NS_VS20_{dt.datetime.now()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
