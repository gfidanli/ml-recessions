{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "cpi = pd.read_csv(\"resources/cpi_final.csv\")\n",
    "gdp = pd.read_csv(\"resources/gdp_final.csv\")\n",
    "gdp_pct = pd.read_csv(\"resources/gdp_pct_chg_final.csv\")\n",
    "houst = pd.read_csv(\"resources/housing_starts_final.csv\")\n",
    "opg = pd.read_csv(\"resources/output_gap_final.csv\")\n",
    "rec_dt = pd.read_csv(\"resources/recession_dates_final.csv\")\n",
    "unrate = pd.read_csv(\"resources/unemployment_rate_final.csv\")\n",
    "fed_funds = pd.read_csv(\"resources/fed_funds_final.csv\")\n",
    "yield10_2 = pd.read_csv(\"resources/10YT_minus_2YT_final.csv\")\n",
    "fred = pd.read_csv(\"resources/FRED_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data sets into one data frame\n",
    "dfs = [cpi, gdp, gdp_pct, houst, opg, rec_dt, unrate, fed_funds, yield10_2, fred]\n",
    "df = reduce(lambda left,right: pd.merge(left,right,on=['quarter'],how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date columns\n",
    "df = df.drop(columns=['date_x','date_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data frame by quarter\n",
    "df = df.sort_values(by=['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to quarter\n",
    "df = df.set_index('quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_consumer_price_index</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdp_pct_change</th>\n",
       "      <th>avg_housing_starts</th>\n",
       "      <th>output_gap</th>\n",
       "      <th>recession_actual</th>\n",
       "      <th>avg_unemployment_rate</th>\n",
       "      <th>fed_funds_avg_rate</th>\n",
       "      <th>fed_funds_percent_change_prev_quarter</th>\n",
       "      <th>fed_funds_st_dev_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>10YT_minus_2YT_percent_change_prev_quarter</th>\n",
       "      <th>real_disp_pers_inc</th>\n",
       "      <th>personal_consumption_exp_excl_food_energy</th>\n",
       "      <th>cpi_US_total</th>\n",
       "      <th>tot_public_debt_as_pct_of_gdp</th>\n",
       "      <th>gross_private_domestic_invest</th>\n",
       "      <th>M2_velocity</th>\n",
       "      <th>median_sls_price_houses_sold_US</th>\n",
       "      <th>nat_rate_of_unemp_long_term</th>\n",
       "      <th>personal_consumption_expenditures</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1976Q3</th>\n",
       "      <td>57.300000</td>\n",
       "      <td>1886.558</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1557.000000</td>\n",
       "      <td>-2.199151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.283478</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.100618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370833</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.518087</td>\n",
       "      <td>33.64333</td>\n",
       "      <td>328.307</td>\n",
       "      <td>1.717</td>\n",
       "      <td>44400.0</td>\n",
       "      <td>6.217</td>\n",
       "      <td>1158.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976Q4</th>\n",
       "      <td>58.133333</td>\n",
       "      <td>1934.273</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1691.333333</td>\n",
       "      <td>-2.246705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>4.874239</td>\n",
       "      <td>-0.077456</td>\n",
       "      <td>0.211941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337386</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.069403</td>\n",
       "      <td>33.78753</td>\n",
       "      <td>337.650</td>\n",
       "      <td>1.699</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>6.223</td>\n",
       "      <td>1192.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977Q1</th>\n",
       "      <td>59.200000</td>\n",
       "      <td>1988.648</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1844.333333</td>\n",
       "      <td>-1.877175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.233333</td>\n",
       "      <td>4.660667</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>0.148254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095455</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.857741</td>\n",
       "      <td>33.65136</td>\n",
       "      <td>360.313</td>\n",
       "      <td>1.689</td>\n",
       "      <td>46300.0</td>\n",
       "      <td>6.227</td>\n",
       "      <td>1228.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977Q2</th>\n",
       "      <td>60.233333</td>\n",
       "      <td>2055.909</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1918.666667</td>\n",
       "      <td>-0.776696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>5.157473</td>\n",
       "      <td>0.106595</td>\n",
       "      <td>0.332835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052764</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.847698</td>\n",
       "      <td>32.80422</td>\n",
       "      <td>389.703</td>\n",
       "      <td>1.701</td>\n",
       "      <td>48900.0</td>\n",
       "      <td>6.232</td>\n",
       "      <td>1255.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977Q3</th>\n",
       "      <td>61.066667</td>\n",
       "      <td>2118.473</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.186001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>5.816413</td>\n",
       "      <td>0.127764</td>\n",
       "      <td>0.344309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342175</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.682162</td>\n",
       "      <td>32.98791</td>\n",
       "      <td>414.134</td>\n",
       "      <td>1.713</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>6.235</td>\n",
       "      <td>1286.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_consumer_price_index       gdp  gdp_pct_change  \\\n",
       "quarter                                                       \n",
       "1976Q3                  57.300000  1886.558             7.6   \n",
       "1976Q4                  58.133333  1934.273            10.5   \n",
       "1977Q1                  59.200000  1988.648            11.7   \n",
       "1977Q2                  60.233333  2055.909            14.2   \n",
       "1977Q3                  61.066667  2118.473            12.7   \n",
       "\n",
       "         avg_housing_starts  output_gap  recession_actual  \\\n",
       "quarter                                                     \n",
       "1976Q3          1557.000000   -2.199151               0.0   \n",
       "1976Q4          1691.333333   -2.246705               0.0   \n",
       "1977Q1          1844.333333   -1.877175               0.0   \n",
       "1977Q2          1918.666667   -0.776696               0.0   \n",
       "1977Q3          2009.000000    0.186001               0.0   \n",
       "\n",
       "         avg_unemployment_rate  fed_funds_avg_rate  \\\n",
       "quarter                                              \n",
       "1976Q3                7.600000            5.283478   \n",
       "1976Q4                7.333333            4.874239   \n",
       "1977Q1                8.233333            4.660667   \n",
       "1977Q2                6.933333            5.157473   \n",
       "1977Q3                6.800000            5.816413   \n",
       "\n",
       "         fed_funds_percent_change_prev_quarter  fed_funds_st_dev_rate  ...  \\\n",
       "quarter                                                                ...   \n",
       "1976Q3                                0.016956               0.100618  ...   \n",
       "1976Q4                               -0.077456               0.211941  ...   \n",
       "1977Q1                               -0.043817               0.148254  ...   \n",
       "1977Q2                                0.106595               0.332835  ...   \n",
       "1977Q3                                0.127764               0.344309  ...   \n",
       "\n",
       "         10YT_minus_2YT_percent_change_prev_quarter  real_disp_pers_inc  \\\n",
       "quarter                                                                   \n",
       "1976Q3                                     0.370833                 3.2   \n",
       "1976Q4                                     0.337386                 2.6   \n",
       "1977Q1                                    -0.095455                 0.9   \n",
       "1977Q2                                    -0.052764                 3.8   \n",
       "1977Q3                                    -0.342175                 5.7   \n",
       "\n",
       "         personal_consumption_exp_excl_food_energy  cpi_US_total  \\\n",
       "quarter                                                            \n",
       "1976Q3                                         6.0      5.518087   \n",
       "1976Q4                                         6.0      5.069403   \n",
       "1977Q1                                         6.2      5.857741   \n",
       "1977Q2                                         6.5      6.847698   \n",
       "1977Q3                                         6.6      6.682162   \n",
       "\n",
       "         tot_public_debt_as_pct_of_gdp  gross_private_domestic_invest  \\\n",
       "quarter                                                                 \n",
       "1976Q3                        33.64333                        328.307   \n",
       "1976Q4                        33.78753                        337.650   \n",
       "1977Q1                        33.65136                        360.313   \n",
       "1977Q2                        32.80422                        389.703   \n",
       "1977Q3                        32.98791                        414.134   \n",
       "\n",
       "         M2_velocity  median_sls_price_houses_sold_US  \\\n",
       "quarter                                                 \n",
       "1976Q3         1.717                          44400.0   \n",
       "1976Q4         1.699                          45500.0   \n",
       "1977Q1         1.689                          46300.0   \n",
       "1977Q2         1.701                          48900.0   \n",
       "1977Q3         1.713                          48800.0   \n",
       "\n",
       "         nat_rate_of_unemp_long_term  personal_consumption_expenditures  \n",
       "quarter                                                                  \n",
       "1976Q3                         6.217                           1158.806  \n",
       "1976Q4                         6.223                           1192.408  \n",
       "1977Q1                         6.227                           1228.212  \n",
       "1977Q2                         6.232                           1255.980  \n",
       "1977Q3                         6.235                           1286.905  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename target column\n",
    "df = df.rename(columns={'target':'recession_actual'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift data with sliding window technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recession_1q_out'] = df['recession_actual'].shift(-1)\n",
    "df['recession_2q_out'] = df['recession_actual'].shift(-2)\n",
    "df['recession_4q_out'] = df['recession_actual'].shift(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three datasets -- 1 for each model (recession 1Qtr out, 2Qtrs out, 4Qtrs out)\n",
    "df_q1 = df.drop(columns=['recession_2q_out','recession_4q_out','recession_actual'])\n",
    "df_q2 = df.drop(columns=['recession_4q_out','recession_1q_out','recession_actual'])\n",
    "df_q4 = df.drop(columns=['recession_1q_out','recession_2q_out','recession_actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values\n",
    "df_q1 = df_q1.dropna()\n",
    "df_q2 = df_q2.dropna()\n",
    "df_q4 = df_q4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y1 = df_q1['recession_1q_out']\n",
    "y2 = df_q2['recession_2q_out']\n",
    "y3 = df_q4['recession_4q_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target\n",
    "df_q1 = df_q1.drop(columns=['recession_1q_out'])\n",
    "df_q2 = df_q2.drop(columns=['recession_2q_out'])\n",
    "df_q4 = df_q4.drop(columns=['recession_4q_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X\n",
    "X_q1 = df_q1\n",
    "X_q2 = df_q2\n",
    "X_q4 = df_q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X1_train, X1_test, y1_train, y1_test=train_test_split(X_q1, y1, train_size=0.8, random_state=42, stratify=y1)\n",
    "X2_train, X2_test, y2_train, y2_test=train_test_split(X_q2, y2, train_size=0.8, random_state=42, stratify=y2)\n",
    "X3_train, X3_test, y3_train, y3_test=train_test_split(X_q4, y3, train_size=0.8, random_state=42, stratify=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create scaler object\n",
    "X1_scaler = StandardScaler().fit(X1_train)\n",
    "X2_scaler = StandardScaler().fit(X2_train)\n",
    "X3_scaler = StandardScaler().fit(X3_train)\n",
    "\n",
    "# X full scaler object\n",
    "X1_full_scaler = StandardScaler().fit(X_q1)\n",
    "X2_full_scaler = StandardScaler().fit(X_q2)\n",
    "X3_full_scaler = StandardScaler().fit(X_q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale training data\n",
    "X1_train_scaled = X1_scaler.transform(X1_train)\n",
    "X2_train_scaled = X2_scaler.transform(X2_train)\n",
    "X3_train_scaled = X3_scaler.transform(X3_train)\n",
    "\n",
    "# Scale testing data\n",
    "X1_test_scaled = X1_scaler.transform(X1_test)\n",
    "X2_test_scaled = X2_scaler.transform(X2_test)\n",
    "X3_test_scaled = X3_scaler.transform(X3_test)\n",
    "\n",
    "# Scale full X data (no splits)\n",
    "X1_full_scaled = X1_full_scaler.transform(X_q1)\n",
    "X2_full_scaled = X2_full_scaler.transform(X_q2)\n",
    "X3_full_scaled = X3_full_scaler.transform(X_q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data to fit LSTM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to reshape data\n",
    "def reshape_data(obj):\n",
    "    reshaped_obj = np.reshape(obj, (obj.shape[0], obj.shape[1], 1))\n",
    "    return reshaped_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training data\n",
    "reshaped_X1_train_scaled = reshape_data(X1_train_scaled)\n",
    "reshaped_X2_train_scaled = reshape_data(X2_train_scaled)\n",
    "reshaped_X3_train_scaled = reshape_data(X3_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape testing data\n",
    "reshaped_X1_test_scaled = reshape_data(X1_test_scaled)\n",
    "reshaped_X2_test_scaled = reshape_data(X2_test_scaled)\n",
    "reshaped_X3_test_scaled = reshape_data(X3_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_full\n",
    "reshaped_X1_full = reshape_data(X1_full_scaled)\n",
    "reshaped_X2_full = reshape_data(X2_full_scaled)\n",
    "reshaped_X3_full = reshape_data(X3_full_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Add layers\n",
    "model.add(LSTM(128, input_shape=(reshaped_X1_train_scaled.shape[1],1), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())  # Normalize activation outputs\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X1-Y1 data (recession 1 quarter out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 28 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "108/108 - 14s - loss: 1.2851 - acc: 0.3519 - val_loss: 0.6892 - val_acc: 0.6429\n",
      "Epoch 2/100\n",
      "108/108 - 1s - loss: 0.7912 - acc: 0.5833 - val_loss: 0.6841 - val_acc: 0.6429\n",
      "Epoch 3/100\n",
      "108/108 - 1s - loss: 0.8677 - acc: 0.5741 - val_loss: 0.6818 - val_acc: 0.6429\n",
      "Epoch 4/100\n",
      "108/108 - 1s - loss: 0.6519 - acc: 0.7037 - val_loss: 0.6801 - val_acc: 0.6429\n",
      "Epoch 5/100\n",
      "108/108 - 1s - loss: 0.6304 - acc: 0.7130 - val_loss: 0.6784 - val_acc: 0.6429\n",
      "Epoch 6/100\n",
      "108/108 - 1s - loss: 0.5673 - acc: 0.7407 - val_loss: 0.6791 - val_acc: 0.6429\n",
      "Epoch 7/100\n",
      "108/108 - 1s - loss: 0.4648 - acc: 0.8056 - val_loss: 0.6803 - val_acc: 0.6429\n",
      "Epoch 8/100\n",
      "108/108 - 1s - loss: 0.4089 - acc: 0.8704 - val_loss: 0.6797 - val_acc: 0.6429\n",
      "Epoch 9/100\n",
      "108/108 - 1s - loss: 0.4715 - acc: 0.7778 - val_loss: 0.6804 - val_acc: 0.6429\n",
      "Epoch 10/100\n",
      "108/108 - 1s - loss: 0.4449 - acc: 0.8056 - val_loss: 0.6830 - val_acc: 0.6429\n",
      "Epoch 11/100\n",
      "108/108 - 1s - loss: 0.4607 - acc: 0.7593 - val_loss: 0.6891 - val_acc: 0.6429\n",
      "Epoch 12/100\n",
      "108/108 - 1s - loss: 0.3362 - acc: 0.8981 - val_loss: 0.6967 - val_acc: 0.6429\n",
      "Epoch 13/100\n",
      "108/108 - 1s - loss: 0.3544 - acc: 0.8611 - val_loss: 0.7043 - val_acc: 0.6429\n",
      "Epoch 14/100\n",
      "108/108 - 1s - loss: 0.3331 - acc: 0.8611 - val_loss: 0.7115 - val_acc: 0.6429\n",
      "Epoch 15/100\n",
      "108/108 - 1s - loss: 0.3198 - acc: 0.8519 - val_loss: 0.7174 - val_acc: 0.6429\n",
      "Epoch 16/100\n",
      "108/108 - 1s - loss: 0.4236 - acc: 0.8241 - val_loss: 0.7212 - val_acc: 0.6429\n",
      "Epoch 17/100\n",
      "108/108 - 1s - loss: 0.3856 - acc: 0.8426 - val_loss: 0.7231 - val_acc: 0.6429\n",
      "Epoch 18/100\n",
      "108/108 - 1s - loss: 0.3172 - acc: 0.8519 - val_loss: 0.7301 - val_acc: 0.6429\n",
      "Epoch 19/100\n",
      "108/108 - 1s - loss: 0.3627 - acc: 0.8704 - val_loss: 0.7416 - val_acc: 0.6429\n",
      "Epoch 20/100\n",
      "108/108 - 1s - loss: 0.2672 - acc: 0.8704 - val_loss: 0.7549 - val_acc: 0.6429\n",
      "Epoch 21/100\n",
      "108/108 - 1s - loss: 0.3224 - acc: 0.8889 - val_loss: 0.7663 - val_acc: 0.6429\n",
      "Epoch 22/100\n",
      "108/108 - 1s - loss: 0.2802 - acc: 0.8796 - val_loss: 0.7788 - val_acc: 0.6429\n",
      "Epoch 23/100\n",
      "108/108 - 1s - loss: 0.3584 - acc: 0.8704 - val_loss: 0.7898 - val_acc: 0.6429\n",
      "Epoch 24/100\n",
      "108/108 - 1s - loss: 0.3022 - acc: 0.8889 - val_loss: 0.8071 - val_acc: 0.6429\n",
      "Epoch 25/100\n",
      "108/108 - 1s - loss: 0.3527 - acc: 0.8704 - val_loss: 0.8239 - val_acc: 0.6429\n",
      "Epoch 26/100\n",
      "108/108 - 1s - loss: 0.2517 - acc: 0.8704 - val_loss: 0.8428 - val_acc: 0.6429\n",
      "Epoch 27/100\n",
      "108/108 - 1s - loss: 0.3368 - acc: 0.8611 - val_loss: 0.8642 - val_acc: 0.6429\n",
      "Epoch 28/100\n",
      "108/108 - 1s - loss: 0.3110 - acc: 0.8796 - val_loss: 0.8720 - val_acc: 0.6429\n",
      "Epoch 29/100\n",
      "108/108 - 1s - loss: 0.3258 - acc: 0.8519 - val_loss: 0.8929 - val_acc: 0.6429\n",
      "Epoch 30/100\n",
      "108/108 - 1s - loss: 0.1950 - acc: 0.9352 - val_loss: 0.9192 - val_acc: 0.6429\n",
      "Epoch 31/100\n",
      "108/108 - 1s - loss: 0.2928 - acc: 0.8333 - val_loss: 0.9447 - val_acc: 0.6429\n",
      "Epoch 32/100\n",
      "108/108 - 1s - loss: 0.2872 - acc: 0.8889 - val_loss: 0.9665 - val_acc: 0.6429\n",
      "Epoch 33/100\n",
      "108/108 - 1s - loss: 0.2575 - acc: 0.9074 - val_loss: 0.9941 - val_acc: 0.6429\n",
      "Epoch 34/100\n",
      "108/108 - 1s - loss: 0.2708 - acc: 0.8796 - val_loss: 1.0145 - val_acc: 0.6429\n",
      "Epoch 35/100\n",
      "108/108 - 1s - loss: 0.3129 - acc: 0.8981 - val_loss: 1.0392 - val_acc: 0.6429\n",
      "Epoch 36/100\n",
      "108/108 - 1s - loss: 0.2389 - acc: 0.8981 - val_loss: 1.0480 - val_acc: 0.6429\n",
      "Epoch 37/100\n",
      "108/108 - 1s - loss: 0.2274 - acc: 0.9167 - val_loss: 1.0597 - val_acc: 0.6429\n",
      "Epoch 38/100\n",
      "108/108 - 1s - loss: 0.3989 - acc: 0.8611 - val_loss: 1.1006 - val_acc: 0.6429\n",
      "Epoch 39/100\n",
      "108/108 - 1s - loss: 0.2972 - acc: 0.8889 - val_loss: 1.1438 - val_acc: 0.6429\n",
      "Epoch 40/100\n",
      "108/108 - 1s - loss: 0.2866 - acc: 0.9167 - val_loss: 1.1687 - val_acc: 0.6429\n",
      "Epoch 41/100\n",
      "108/108 - 1s - loss: 0.2905 - acc: 0.8796 - val_loss: 1.1861 - val_acc: 0.6429\n",
      "Epoch 42/100\n",
      "108/108 - 1s - loss: 0.2600 - acc: 0.8981 - val_loss: 1.1697 - val_acc: 0.6429\n",
      "Epoch 43/100\n",
      "108/108 - 1s - loss: 0.2469 - acc: 0.9167 - val_loss: 1.1890 - val_acc: 0.6429\n",
      "Epoch 44/100\n",
      "108/108 - 1s - loss: 0.1943 - acc: 0.9444 - val_loss: 1.2262 - val_acc: 0.6429\n",
      "Epoch 45/100\n",
      "108/108 - 1s - loss: 0.2287 - acc: 0.9074 - val_loss: 1.2520 - val_acc: 0.6429\n",
      "Epoch 46/100\n",
      "108/108 - 1s - loss: 0.2153 - acc: 0.9167 - val_loss: 1.2954 - val_acc: 0.6429\n",
      "Epoch 47/100\n",
      "108/108 - 1s - loss: 0.2072 - acc: 0.8981 - val_loss: 1.3472 - val_acc: 0.6429\n",
      "Epoch 48/100\n",
      "108/108 - 1s - loss: 0.2206 - acc: 0.8981 - val_loss: 1.3840 - val_acc: 0.6429\n",
      "Epoch 49/100\n",
      "108/108 - 1s - loss: 0.2698 - acc: 0.8981 - val_loss: 1.4483 - val_acc: 0.6429\n",
      "Epoch 50/100\n",
      "108/108 - 1s - loss: 0.2470 - acc: 0.8981 - val_loss: 1.4603 - val_acc: 0.6429\n",
      "Epoch 51/100\n",
      "108/108 - 1s - loss: 0.1767 - acc: 0.9167 - val_loss: 1.4611 - val_acc: 0.6429\n",
      "Epoch 52/100\n",
      "108/108 - 1s - loss: 0.2446 - acc: 0.8981 - val_loss: 1.4540 - val_acc: 0.6429\n",
      "Epoch 53/100\n",
      "108/108 - 1s - loss: 0.2133 - acc: 0.9352 - val_loss: 1.5073 - val_acc: 0.6429\n",
      "Epoch 54/100\n",
      "108/108 - 1s - loss: 0.1865 - acc: 0.9259 - val_loss: 1.5516 - val_acc: 0.6429\n",
      "Epoch 55/100\n",
      "108/108 - 1s - loss: 0.1946 - acc: 0.9074 - val_loss: 1.6246 - val_acc: 0.6429\n",
      "Epoch 56/100\n",
      "108/108 - 1s - loss: 0.1662 - acc: 0.9259 - val_loss: 1.6868 - val_acc: 0.6429\n",
      "Epoch 57/100\n",
      "108/108 - 1s - loss: 0.2340 - acc: 0.8981 - val_loss: 1.7160 - val_acc: 0.6429\n",
      "Epoch 58/100\n",
      "108/108 - 1s - loss: 0.2507 - acc: 0.9259 - val_loss: 1.7260 - val_acc: 0.6429\n",
      "Epoch 59/100\n",
      "108/108 - 1s - loss: 0.1833 - acc: 0.9167 - val_loss: 1.7615 - val_acc: 0.6429\n",
      "Epoch 60/100\n",
      "108/108 - 1s - loss: 0.1862 - acc: 0.8889 - val_loss: 1.7700 - val_acc: 0.6429\n",
      "Epoch 61/100\n",
      "108/108 - 1s - loss: 0.2580 - acc: 0.8704 - val_loss: 1.8114 - val_acc: 0.6429\n",
      "Epoch 62/100\n",
      "108/108 - 1s - loss: 0.1745 - acc: 0.9259 - val_loss: 1.8743 - val_acc: 0.6429\n",
      "Epoch 63/100\n",
      "108/108 - 1s - loss: 0.1936 - acc: 0.9259 - val_loss: 1.9078 - val_acc: 0.6429\n",
      "Epoch 64/100\n",
      "108/108 - 1s - loss: 0.1871 - acc: 0.9352 - val_loss: 1.9245 - val_acc: 0.6429\n",
      "Epoch 65/100\n",
      "108/108 - 1s - loss: 0.2319 - acc: 0.9167 - val_loss: 1.8993 - val_acc: 0.6429\n",
      "Epoch 66/100\n",
      "108/108 - 1s - loss: 0.1820 - acc: 0.9167 - val_loss: 1.8343 - val_acc: 0.6429\n",
      "Epoch 67/100\n",
      "108/108 - 1s - loss: 0.1929 - acc: 0.9259 - val_loss: 1.6914 - val_acc: 0.6429\n",
      "Epoch 68/100\n",
      "108/108 - 1s - loss: 0.1854 - acc: 0.9259 - val_loss: 1.6557 - val_acc: 0.6429\n",
      "Epoch 69/100\n",
      "108/108 - 1s - loss: 0.2106 - acc: 0.9167 - val_loss: 1.7303 - val_acc: 0.6429\n",
      "Epoch 70/100\n",
      "108/108 - 1s - loss: 0.1554 - acc: 0.9352 - val_loss: 1.8594 - val_acc: 0.6429\n",
      "Epoch 71/100\n",
      "108/108 - 1s - loss: 0.2434 - acc: 0.8611 - val_loss: 1.8428 - val_acc: 0.6429\n",
      "Epoch 72/100\n",
      "108/108 - 1s - loss: 0.2048 - acc: 0.9444 - val_loss: 1.8061 - val_acc: 0.6429\n",
      "Epoch 73/100\n",
      "108/108 - 1s - loss: 0.1994 - acc: 0.9167 - val_loss: 1.8181 - val_acc: 0.6429\n",
      "Epoch 74/100\n",
      "108/108 - 1s - loss: 0.1825 - acc: 0.9259 - val_loss: 1.9245 - val_acc: 0.6429\n",
      "Epoch 75/100\n",
      "108/108 - 1s - loss: 0.2017 - acc: 0.9259 - val_loss: 2.0875 - val_acc: 0.6429\n",
      "Epoch 76/100\n",
      "108/108 - 1s - loss: 0.1803 - acc: 0.9167 - val_loss: 2.1792 - val_acc: 0.6429\n",
      "Epoch 77/100\n",
      "108/108 - 1s - loss: 0.1803 - acc: 0.9259 - val_loss: 2.2005 - val_acc: 0.6429\n",
      "Epoch 78/100\n",
      "108/108 - 1s - loss: 0.1682 - acc: 0.9167 - val_loss: 2.1689 - val_acc: 0.6429\n",
      "Epoch 79/100\n",
      "108/108 - 1s - loss: 0.1356 - acc: 0.9444 - val_loss: 2.2092 - val_acc: 0.6429\n",
      "Epoch 80/100\n",
      "108/108 - 1s - loss: 0.1760 - acc: 0.9259 - val_loss: 2.2547 - val_acc: 0.6429\n",
      "Epoch 81/100\n",
      "108/108 - 1s - loss: 0.2351 - acc: 0.9074 - val_loss: 2.2593 - val_acc: 0.6429\n",
      "Epoch 82/100\n",
      "108/108 - 1s - loss: 0.1874 - acc: 0.9259 - val_loss: 2.1291 - val_acc: 0.6429\n",
      "Epoch 83/100\n",
      "108/108 - 1s - loss: 0.1960 - acc: 0.9352 - val_loss: 2.0177 - val_acc: 0.6429\n",
      "Epoch 84/100\n",
      "108/108 - 1s - loss: 0.1542 - acc: 0.9444 - val_loss: 1.9924 - val_acc: 0.7143\n",
      "Epoch 85/100\n",
      "108/108 - 1s - loss: 0.1700 - acc: 0.9259 - val_loss: 1.8790 - val_acc: 0.7143\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 1s - loss: 0.1807 - acc: 0.9537 - val_loss: 1.6939 - val_acc: 0.6786\n",
      "Epoch 87/100\n",
      "108/108 - 1s - loss: 0.2401 - acc: 0.9074 - val_loss: 1.6681 - val_acc: 0.6786\n",
      "Epoch 88/100\n",
      "108/108 - 1s - loss: 0.1885 - acc: 0.9352 - val_loss: 1.6711 - val_acc: 0.6786\n",
      "Epoch 89/100\n",
      "108/108 - 1s - loss: 0.1413 - acc: 0.9352 - val_loss: 1.6573 - val_acc: 0.6786\n",
      "Epoch 90/100\n",
      "108/108 - 1s - loss: 0.1945 - acc: 0.9352 - val_loss: 1.5825 - val_acc: 0.7143\n",
      "Epoch 91/100\n",
      "108/108 - 1s - loss: 0.1729 - acc: 0.9352 - val_loss: 1.5766 - val_acc: 0.7143\n",
      "Epoch 92/100\n",
      "108/108 - 1s - loss: 0.1884 - acc: 0.9352 - val_loss: 1.5388 - val_acc: 0.6786\n",
      "Epoch 93/100\n",
      "108/108 - 1s - loss: 0.2434 - acc: 0.9352 - val_loss: 1.6082 - val_acc: 0.6786\n",
      "Epoch 94/100\n",
      "108/108 - 1s - loss: 0.1670 - acc: 0.9167 - val_loss: 1.6294 - val_acc: 0.7143\n",
      "Epoch 95/100\n",
      "108/108 - 1s - loss: 0.1222 - acc: 0.9630 - val_loss: 1.6474 - val_acc: 0.7143\n",
      "Epoch 96/100\n",
      "108/108 - 1s - loss: 0.1484 - acc: 0.9352 - val_loss: 1.6099 - val_acc: 0.7143\n",
      "Epoch 97/100\n",
      "108/108 - 1s - loss: 0.1743 - acc: 0.9259 - val_loss: 1.4932 - val_acc: 0.7143\n",
      "Epoch 98/100\n",
      "108/108 - 1s - loss: 0.1324 - acc: 0.9444 - val_loss: 1.4335 - val_acc: 0.7143\n",
      "Epoch 99/100\n",
      "108/108 - 1s - loss: 0.1221 - acc: 0.9630 - val_loss: 1.4522 - val_acc: 0.6786\n",
      "Epoch 100/100\n",
      "108/108 - 1s - loss: 0.1738 - acc: 0.9444 - val_loss: 1.6584 - val_acc: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3ce55a58>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X1_train_scaled, y1_train, validation_split=0.2, epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 1.0003 - acc: 0.8529\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss1, model_accuracy1 = model.evaluate(reshaped_X1_test_scaled, y1_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions1 = model.predict_classes(reshaped_X1_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "one_qtr_out = pd.DataFrame({\"Predicted\":predictions1, \"Actual\":y1_test})\n",
    "# one_qtr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name1 = f\"shuffled-1q-out-{int(dt.datetime.now())}\"\n",
    "model.save(f\"models/{name1}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X1_full = model.predict_classes(reshaped_X1_full)\n",
    "X1_full_results = pd.DataFrame({\"Predicted\":pred_X1_full, \"Actual\":y1})\n",
    "X1_full_results.to_csv(f\"resources/predictions/X1_full_shuffled_{int(dt.datetime.now())}.csv\")\n",
    "# X1_full_results.loc[X1_full_results[\"Actual\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X1-Y1 data (recession 1 quarter out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0]\n",
      " [ 5  0]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X1 model\n",
    "con_mat = confusion_matrix(y1_test, predictions1)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92        29\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.43      0.50      0.46        34\n",
      "weighted avg       0.73      0.85      0.79        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y1_test, predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X2-Y2 data (recession 2 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 - 2s - loss: 0.4598 - acc: 0.8796 - val_loss: 1.5380 - val_acc: 0.6296\n",
      "Epoch 2/100\n",
      "108/108 - 2s - loss: 0.3847 - acc: 0.9167 - val_loss: 1.4471 - val_acc: 0.6667\n",
      "Epoch 3/100\n",
      "108/108 - 2s - loss: 0.4034 - acc: 0.8796 - val_loss: 1.4798 - val_acc: 0.6667\n",
      "Epoch 4/100\n",
      "108/108 - 1s - loss: 0.3588 - acc: 0.9074 - val_loss: 1.4635 - val_acc: 0.6667\n",
      "Epoch 5/100\n",
      "108/108 - 2s - loss: 0.4300 - acc: 0.8889 - val_loss: 1.5156 - val_acc: 0.6667\n",
      "Epoch 6/100\n",
      "108/108 - 2s - loss: 0.2173 - acc: 0.9259 - val_loss: 1.6702 - val_acc: 0.6296\n",
      "Epoch 7/100\n",
      "108/108 - 1s - loss: 0.2427 - acc: 0.9167 - val_loss: 1.7026 - val_acc: 0.6296\n",
      "Epoch 8/100\n",
      "108/108 - 2s - loss: 0.2810 - acc: 0.9074 - val_loss: 1.6614 - val_acc: 0.6667\n",
      "Epoch 9/100\n",
      "108/108 - 2s - loss: 0.2784 - acc: 0.8889 - val_loss: 1.5880 - val_acc: 0.6667\n",
      "Epoch 10/100\n",
      "108/108 - 2s - loss: 0.1753 - acc: 0.9352 - val_loss: 1.4921 - val_acc: 0.6667\n",
      "Epoch 11/100\n",
      "108/108 - 2s - loss: 0.2404 - acc: 0.8796 - val_loss: 1.4614 - val_acc: 0.6667\n",
      "Epoch 12/100\n",
      "108/108 - 2s - loss: 0.1809 - acc: 0.9444 - val_loss: 1.5100 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "108/108 - 2s - loss: 0.2520 - acc: 0.9167 - val_loss: 1.5886 - val_acc: 0.6667\n",
      "Epoch 14/100\n",
      "108/108 - 2s - loss: 0.1987 - acc: 0.9352 - val_loss: 1.5993 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      "108/108 - 2s - loss: 0.2022 - acc: 0.9444 - val_loss: 1.6797 - val_acc: 0.6296\n",
      "Epoch 16/100\n",
      "108/108 - 2s - loss: 0.2055 - acc: 0.9259 - val_loss: 1.6965 - val_acc: 0.6296\n",
      "Epoch 17/100\n",
      "108/108 - 2s - loss: 0.2286 - acc: 0.9352 - val_loss: 1.5185 - val_acc: 0.6296\n",
      "Epoch 18/100\n",
      "108/108 - 2s - loss: 0.1432 - acc: 0.9630 - val_loss: 1.3746 - val_acc: 0.6296\n",
      "Epoch 19/100\n",
      "108/108 - 2s - loss: 0.2275 - acc: 0.9167 - val_loss: 1.3609 - val_acc: 0.6667\n",
      "Epoch 20/100\n",
      "108/108 - 2s - loss: 0.2205 - acc: 0.9444 - val_loss: 1.3040 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "108/108 - 2s - loss: 0.1506 - acc: 0.9537 - val_loss: 1.2916 - val_acc: 0.6296\n",
      "Epoch 22/100\n",
      "108/108 - 3s - loss: 0.2495 - acc: 0.9167 - val_loss: 1.3340 - val_acc: 0.5926\n",
      "Epoch 23/100\n",
      "108/108 - 3s - loss: 0.1339 - acc: 0.9352 - val_loss: 1.3940 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "108/108 - 3s - loss: 0.1816 - acc: 0.9352 - val_loss: 1.4146 - val_acc: 0.5926\n",
      "Epoch 25/100\n",
      "108/108 - 3s - loss: 0.1768 - acc: 0.9352 - val_loss: 1.4513 - val_acc: 0.5926\n",
      "Epoch 26/100\n",
      "108/108 - 2s - loss: 0.1837 - acc: 0.9722 - val_loss: 1.5641 - val_acc: 0.6296\n",
      "Epoch 27/100\n",
      "108/108 - 2s - loss: 0.1542 - acc: 0.9537 - val_loss: 1.6004 - val_acc: 0.6296\n",
      "Epoch 28/100\n",
      "108/108 - 2s - loss: 0.1812 - acc: 0.9444 - val_loss: 1.5921 - val_acc: 0.6296\n",
      "Epoch 29/100\n",
      "108/108 - 2s - loss: 0.1537 - acc: 0.9444 - val_loss: 1.5422 - val_acc: 0.6296\n",
      "Epoch 30/100\n",
      "108/108 - 2s - loss: 0.1797 - acc: 0.9722 - val_loss: 1.3566 - val_acc: 0.6296\n",
      "Epoch 31/100\n",
      "108/108 - 2s - loss: 0.1271 - acc: 0.9722 - val_loss: 1.1576 - val_acc: 0.6667\n",
      "Epoch 32/100\n",
      "108/108 - 2s - loss: 0.1754 - acc: 0.9444 - val_loss: 1.0789 - val_acc: 0.6667\n",
      "Epoch 33/100\n",
      "108/108 - 2s - loss: 0.1880 - acc: 0.9630 - val_loss: 1.0662 - val_acc: 0.6667\n",
      "Epoch 34/100\n",
      "108/108 - 2s - loss: 0.2376 - acc: 0.9167 - val_loss: 1.0868 - val_acc: 0.7037\n",
      "Epoch 35/100\n",
      "108/108 - 2s - loss: 0.1512 - acc: 0.9352 - val_loss: 1.1701 - val_acc: 0.6296\n",
      "Epoch 36/100\n",
      "108/108 - 2s - loss: 0.1397 - acc: 0.9537 - val_loss: 1.2381 - val_acc: 0.5926\n",
      "Epoch 37/100\n",
      "108/108 - 2s - loss: 0.1744 - acc: 0.9444 - val_loss: 1.3078 - val_acc: 0.5926\n",
      "Epoch 38/100\n",
      "108/108 - 2s - loss: 0.1480 - acc: 0.9444 - val_loss: 1.4729 - val_acc: 0.5556\n",
      "Epoch 39/100\n",
      "108/108 - 2s - loss: 0.1529 - acc: 0.9537 - val_loss: 1.7267 - val_acc: 0.5926\n",
      "Epoch 40/100\n",
      "108/108 - 2s - loss: 0.1419 - acc: 0.9444 - val_loss: 1.7407 - val_acc: 0.6296\n",
      "Epoch 41/100\n",
      "108/108 - 2s - loss: 0.1715 - acc: 0.9722 - val_loss: 1.5662 - val_acc: 0.6296\n",
      "Epoch 42/100\n",
      "108/108 - 2s - loss: 0.1466 - acc: 0.9444 - val_loss: 1.5600 - val_acc: 0.6296\n",
      "Epoch 43/100\n",
      "108/108 - 2s - loss: 0.1606 - acc: 0.9444 - val_loss: 1.5778 - val_acc: 0.5926\n",
      "Epoch 44/100\n",
      "108/108 - 2s - loss: 0.1163 - acc: 0.9537 - val_loss: 1.7073 - val_acc: 0.5926\n",
      "Epoch 45/100\n",
      "108/108 - 2s - loss: 0.1435 - acc: 0.9444 - val_loss: 1.7284 - val_acc: 0.6296\n",
      "Epoch 46/100\n",
      "108/108 - 2s - loss: 0.1000 - acc: 0.9630 - val_loss: 1.5953 - val_acc: 0.6296\n",
      "Epoch 47/100\n",
      "108/108 - 2s - loss: 0.0946 - acc: 0.9630 - val_loss: 1.4233 - val_acc: 0.6667\n",
      "Epoch 48/100\n",
      "108/108 - 2s - loss: 0.1906 - acc: 0.9444 - val_loss: 1.4608 - val_acc: 0.6296\n",
      "Epoch 49/100\n",
      "108/108 - 2s - loss: 0.1748 - acc: 0.9352 - val_loss: 1.5439 - val_acc: 0.6296\n",
      "Epoch 50/100\n",
      "108/108 - 2s - loss: 0.1106 - acc: 0.9722 - val_loss: 1.5739 - val_acc: 0.5926\n",
      "Epoch 51/100\n",
      "108/108 - 2s - loss: 0.1689 - acc: 0.9537 - val_loss: 1.6596 - val_acc: 0.5926\n",
      "Epoch 52/100\n",
      "108/108 - 2s - loss: 0.1263 - acc: 0.9630 - val_loss: 1.6988 - val_acc: 0.5926\n",
      "Epoch 53/100\n",
      "108/108 - 2s - loss: 0.0865 - acc: 0.9815 - val_loss: 1.6799 - val_acc: 0.6296\n",
      "Epoch 54/100\n",
      "108/108 - 2s - loss: 0.1000 - acc: 0.9630 - val_loss: 1.6309 - val_acc: 0.6296\n",
      "Epoch 55/100\n",
      "108/108 - 2s - loss: 0.0960 - acc: 0.9722 - val_loss: 1.6048 - val_acc: 0.6667\n",
      "Epoch 56/100\n",
      "108/108 - 2s - loss: 0.1345 - acc: 0.9444 - val_loss: 1.6000 - val_acc: 0.6296\n",
      "Epoch 57/100\n",
      "108/108 - 2s - loss: 0.0718 - acc: 0.9907 - val_loss: 1.5537 - val_acc: 0.6296\n",
      "Epoch 58/100\n",
      "108/108 - 2s - loss: 0.0992 - acc: 0.9722 - val_loss: 1.6998 - val_acc: 0.6296\n",
      "Epoch 59/100\n",
      "108/108 - 2s - loss: 0.0907 - acc: 0.9722 - val_loss: 1.8716 - val_acc: 0.5926\n",
      "Epoch 60/100\n",
      "108/108 - 2s - loss: 0.0577 - acc: 0.9722 - val_loss: 1.9133 - val_acc: 0.5926\n",
      "Epoch 61/100\n",
      "108/108 - 2s - loss: 0.1058 - acc: 0.9815 - val_loss: 1.8262 - val_acc: 0.5926\n",
      "Epoch 62/100\n",
      "108/108 - 2s - loss: 0.1072 - acc: 0.9722 - val_loss: 1.7291 - val_acc: 0.6296\n",
      "Epoch 63/100\n",
      "108/108 - 2s - loss: 0.0823 - acc: 0.9815 - val_loss: 1.7191 - val_acc: 0.6296\n",
      "Epoch 64/100\n",
      "108/108 - 2s - loss: 0.1230 - acc: 0.9444 - val_loss: 1.6768 - val_acc: 0.6667\n",
      "Epoch 65/100\n",
      "108/108 - 2s - loss: 0.1113 - acc: 0.9722 - val_loss: 1.7328 - val_acc: 0.6296\n",
      "Epoch 66/100\n",
      "108/108 - 2s - loss: 0.0636 - acc: 0.9722 - val_loss: 1.7785 - val_acc: 0.6296\n",
      "Epoch 67/100\n",
      "108/108 - 2s - loss: 0.1053 - acc: 0.9722 - val_loss: 1.6655 - val_acc: 0.6296\n",
      "Epoch 68/100\n",
      "108/108 - 2s - loss: 0.0860 - acc: 0.9907 - val_loss: 1.5703 - val_acc: 0.6667\n",
      "Epoch 69/100\n",
      "108/108 - 2s - loss: 0.0632 - acc: 0.9815 - val_loss: 1.5324 - val_acc: 0.6667\n",
      "Epoch 70/100\n",
      "108/108 - 2s - loss: 0.0895 - acc: 0.9907 - val_loss: 1.7612 - val_acc: 0.6296\n",
      "Epoch 71/100\n",
      "108/108 - 2s - loss: 0.0772 - acc: 0.9815 - val_loss: 2.0785 - val_acc: 0.6296\n",
      "Epoch 72/100\n",
      "108/108 - 2s - loss: 0.0873 - acc: 0.9815 - val_loss: 2.2409 - val_acc: 0.6296\n",
      "Epoch 73/100\n",
      "108/108 - 2s - loss: 0.1156 - acc: 0.9722 - val_loss: 2.1008 - val_acc: 0.5926\n",
      "Epoch 74/100\n",
      "108/108 - 2s - loss: 0.1576 - acc: 0.9352 - val_loss: 1.8504 - val_acc: 0.6667\n",
      "Epoch 75/100\n",
      "108/108 - 2s - loss: 0.0539 - acc: 0.9907 - val_loss: 1.6537 - val_acc: 0.6667\n",
      "Epoch 76/100\n",
      "108/108 - 2s - loss: 0.0429 - acc: 1.0000 - val_loss: 1.6337 - val_acc: 0.7037\n",
      "Epoch 77/100\n",
      "108/108 - 2s - loss: 0.0556 - acc: 0.9907 - val_loss: 1.6633 - val_acc: 0.7037\n",
      "Epoch 78/100\n",
      "108/108 - 2s - loss: 0.0829 - acc: 0.9722 - val_loss: 1.7887 - val_acc: 0.7037\n",
      "Epoch 79/100\n",
      "108/108 - 2s - loss: 0.0669 - acc: 0.9722 - val_loss: 2.0057 - val_acc: 0.6667\n",
      "Epoch 80/100\n",
      "108/108 - 2s - loss: 0.0624 - acc: 0.9722 - val_loss: 1.9230 - val_acc: 0.7037\n",
      "Epoch 81/100\n",
      "108/108 - 2s - loss: 0.1316 - acc: 0.9630 - val_loss: 1.8567 - val_acc: 0.6667\n",
      "Epoch 82/100\n",
      "108/108 - 2s - loss: 0.0745 - acc: 0.9815 - val_loss: 1.8604 - val_acc: 0.6667\n",
      "Epoch 83/100\n",
      "108/108 - 2s - loss: 0.0827 - acc: 0.9722 - val_loss: 1.8471 - val_acc: 0.6667\n",
      "Epoch 84/100\n",
      "108/108 - 2s - loss: 0.0414 - acc: 0.9907 - val_loss: 1.8811 - val_acc: 0.6296\n",
      "Epoch 85/100\n",
      "108/108 - 2s - loss: 0.0512 - acc: 0.9907 - val_loss: 1.9214 - val_acc: 0.6296\n",
      "Epoch 86/100\n",
      "108/108 - 2s - loss: 0.0471 - acc: 0.9907 - val_loss: 2.0012 - val_acc: 0.6296\n",
      "Epoch 87/100\n",
      "108/108 - 4s - loss: 0.0880 - acc: 0.9722 - val_loss: 2.0592 - val_acc: 0.6296\n",
      "Epoch 88/100\n",
      "108/108 - 3s - loss: 0.0493 - acc: 0.9815 - val_loss: 2.0443 - val_acc: 0.6296\n",
      "Epoch 89/100\n",
      "108/108 - 3s - loss: 0.0539 - acc: 0.9907 - val_loss: 2.0236 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "108/108 - 3s - loss: 0.0392 - acc: 0.9907 - val_loss: 2.1268 - val_acc: 0.6296\n",
      "Epoch 91/100\n",
      "108/108 - 3s - loss: 0.0303 - acc: 1.0000 - val_loss: 2.1386 - val_acc: 0.6296\n",
      "Epoch 92/100\n",
      "108/108 - 3s - loss: 0.0637 - acc: 0.9815 - val_loss: 2.1945 - val_acc: 0.6296\n",
      "Epoch 93/100\n",
      "108/108 - 2s - loss: 0.0940 - acc: 0.9630 - val_loss: 1.8379 - val_acc: 0.6667\n",
      "Epoch 94/100\n",
      "108/108 - 2s - loss: 0.1112 - acc: 0.9815 - val_loss: 1.1909 - val_acc: 0.7407\n",
      "Epoch 95/100\n",
      "108/108 - 2s - loss: 0.1741 - acc: 0.9630 - val_loss: 1.0212 - val_acc: 0.7037\n",
      "Epoch 96/100\n",
      "108/108 - 3s - loss: 0.0792 - acc: 0.9722 - val_loss: 1.0522 - val_acc: 0.7778\n",
      "Epoch 97/100\n",
      "108/108 - 2s - loss: 0.0735 - acc: 0.9815 - val_loss: 1.2720 - val_acc: 0.7037\n",
      "Epoch 98/100\n",
      "108/108 - 2s - loss: 0.1179 - acc: 0.9722 - val_loss: 1.5257 - val_acc: 0.6296\n",
      "Epoch 99/100\n",
      "108/108 - 2s - loss: 0.0908 - acc: 0.9537 - val_loss: 1.7163 - val_acc: 0.6296\n",
      "Epoch 100/100\n",
      "108/108 - 2s - loss: 0.0902 - acc: 0.9537 - val_loss: 1.8089 - val_acc: 0.6296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3d145cc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X2_train_scaled, y2_train, validation_split=0.2, epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.7892 - acc: 0.8235\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss2, model_accuracy2 = model.evaluate(reshaped_X2_test_scaled, y2_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions2 = model.predict_classes(reshaped_X2_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "two_qtrs_out = pd.DataFrame({\"Predicted\":predictions2, \"Actual\":y2_test})\n",
    "# two_qtrs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name2 = f\"shuffled-2q-out-{int(dt.datetime.now())}\"\n",
    "model.save(f\"models/{name2}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X2_full = model.predict_classes(reshaped_X2_full)\n",
    "X2_full_results = pd.DataFrame({\"Predicted\":pred_X2_full, \"Actual\":y2})\n",
    "X2_full_results.to_csv(f\"resources/predictions/X2_full_shuffled_{int(dt.datetime.now())}.csv\")\n",
    "# X2_full_results.loc[X2_full_results[\"Actual\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X2-Y2 data (recession 2 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2]\n",
      " [ 4  1]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X2 model\n",
    "con_mat = confusion_matrix(y2_test, predictions2)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90        29\n",
      "         1.0       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.60      0.57      0.57        34\n",
      "weighted avg       0.79      0.82      0.80        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y2_test, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X3-Y3 data (recession 4 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "106/106 - 2s - loss: 0.5956 - acc: 0.8679 - val_loss: 1.2949 - val_acc: 0.7407\n",
      "Epoch 2/100\n",
      "106/106 - 2s - loss: 0.5008 - acc: 0.8679 - val_loss: 0.9691 - val_acc: 0.6667\n",
      "Epoch 3/100\n",
      "106/106 - 2s - loss: 0.4562 - acc: 0.8585 - val_loss: 0.9586 - val_acc: 0.6667\n",
      "Epoch 4/100\n",
      "106/106 - 1s - loss: 0.2959 - acc: 0.8868 - val_loss: 1.0320 - val_acc: 0.5926\n",
      "Epoch 5/100\n",
      "106/106 - 1s - loss: 0.2441 - acc: 0.9057 - val_loss: 1.0507 - val_acc: 0.5556\n",
      "Epoch 6/100\n",
      "106/106 - 1s - loss: 0.1599 - acc: 0.9340 - val_loss: 0.9817 - val_acc: 0.5556\n",
      "Epoch 7/100\n",
      "106/106 - 1s - loss: 0.1926 - acc: 0.9245 - val_loss: 0.8635 - val_acc: 0.6667\n",
      "Epoch 8/100\n",
      "106/106 - 2s - loss: 0.2792 - acc: 0.8585 - val_loss: 0.7312 - val_acc: 0.7407\n",
      "Epoch 9/100\n",
      "106/106 - 1s - loss: 0.2775 - acc: 0.9057 - val_loss: 0.6937 - val_acc: 0.7407\n",
      "Epoch 10/100\n",
      "106/106 - 1s - loss: 0.2591 - acc: 0.9057 - val_loss: 0.6463 - val_acc: 0.7778\n",
      "Epoch 11/100\n",
      "106/106 - 1s - loss: 0.1994 - acc: 0.9057 - val_loss: 0.5311 - val_acc: 0.8148\n",
      "Epoch 12/100\n",
      "106/106 - 2s - loss: 0.2488 - acc: 0.8585 - val_loss: 0.5660 - val_acc: 0.7407\n",
      "Epoch 13/100\n",
      "106/106 - 2s - loss: 0.2234 - acc: 0.9057 - val_loss: 0.6152 - val_acc: 0.7778\n",
      "Epoch 14/100\n",
      "106/106 - 2s - loss: 0.1890 - acc: 0.9151 - val_loss: 0.6984 - val_acc: 0.7778\n",
      "Epoch 15/100\n",
      "106/106 - 2s - loss: 0.1952 - acc: 0.9340 - val_loss: 0.8149 - val_acc: 0.8148\n",
      "Epoch 16/100\n",
      "106/106 - 2s - loss: 0.1605 - acc: 0.9245 - val_loss: 0.8579 - val_acc: 0.8148\n",
      "Epoch 17/100\n",
      "106/106 - 2s - loss: 0.2017 - acc: 0.9151 - val_loss: 0.9001 - val_acc: 0.7407\n",
      "Epoch 18/100\n",
      "106/106 - 2s - loss: 0.1281 - acc: 0.9528 - val_loss: 0.9411 - val_acc: 0.7037\n",
      "Epoch 19/100\n",
      "106/106 - 2s - loss: 0.1883 - acc: 0.9245 - val_loss: 0.9582 - val_acc: 0.7037\n",
      "Epoch 20/100\n",
      "106/106 - 2s - loss: 0.1643 - acc: 0.9245 - val_loss: 0.9422 - val_acc: 0.7778\n",
      "Epoch 21/100\n",
      "106/106 - 2s - loss: 0.1585 - acc: 0.9340 - val_loss: 0.9487 - val_acc: 0.7778\n",
      "Epoch 22/100\n",
      "106/106 - 2s - loss: 0.1918 - acc: 0.8868 - val_loss: 0.9883 - val_acc: 0.8148\n",
      "Epoch 23/100\n",
      "106/106 - 2s - loss: 0.1495 - acc: 0.9245 - val_loss: 0.9801 - val_acc: 0.8148\n",
      "Epoch 24/100\n",
      "106/106 - 1s - loss: 0.1424 - acc: 0.9340 - val_loss: 0.9709 - val_acc: 0.8148\n",
      "Epoch 25/100\n",
      "106/106 - 2s - loss: 0.1709 - acc: 0.9340 - val_loss: 0.9309 - val_acc: 0.8148\n",
      "Epoch 26/100\n",
      "106/106 - 2s - loss: 0.1157 - acc: 0.9717 - val_loss: 0.9969 - val_acc: 0.7778\n",
      "Epoch 27/100\n",
      "106/106 - 2s - loss: 0.1408 - acc: 0.9245 - val_loss: 1.0426 - val_acc: 0.8148\n",
      "Epoch 28/100\n",
      "106/106 - 2s - loss: 0.1526 - acc: 0.9528 - val_loss: 1.0985 - val_acc: 0.8148\n",
      "Epoch 29/100\n",
      "106/106 - 2s - loss: 0.1514 - acc: 0.9434 - val_loss: 1.1301 - val_acc: 0.8148\n",
      "Epoch 30/100\n",
      "106/106 - 2s - loss: 0.1727 - acc: 0.9151 - val_loss: 1.1106 - val_acc: 0.8148\n",
      "Epoch 31/100\n",
      "106/106 - 1s - loss: 0.1394 - acc: 0.9623 - val_loss: 0.9974 - val_acc: 0.8148\n",
      "Epoch 32/100\n",
      "106/106 - 2s - loss: 0.1421 - acc: 0.9434 - val_loss: 1.0179 - val_acc: 0.7778\n",
      "Epoch 33/100\n",
      "106/106 - 2s - loss: 0.1394 - acc: 0.9528 - val_loss: 1.0913 - val_acc: 0.7778\n",
      "Epoch 34/100\n",
      "106/106 - 2s - loss: 0.1872 - acc: 0.9057 - val_loss: 1.1308 - val_acc: 0.8148\n",
      "Epoch 35/100\n",
      "106/106 - 2s - loss: 0.1266 - acc: 0.9245 - val_loss: 1.2125 - val_acc: 0.8148\n",
      "Epoch 36/100\n",
      "106/106 - 1s - loss: 0.1314 - acc: 0.9057 - val_loss: 1.2591 - val_acc: 0.8148\n",
      "Epoch 37/100\n",
      "106/106 - 1s - loss: 0.1147 - acc: 0.9623 - val_loss: 1.2531 - val_acc: 0.8148\n",
      "Epoch 38/100\n",
      "106/106 - 2s - loss: 0.1701 - acc: 0.9434 - val_loss: 1.2197 - val_acc: 0.8148\n",
      "Epoch 39/100\n",
      "106/106 - 2s - loss: 0.1099 - acc: 0.9528 - val_loss: 1.2366 - val_acc: 0.7778\n",
      "Epoch 40/100\n",
      "106/106 - 2s - loss: 0.1146 - acc: 0.9434 - val_loss: 1.2659 - val_acc: 0.7778\n",
      "Epoch 41/100\n",
      "106/106 - 2s - loss: 0.1239 - acc: 0.9434 - val_loss: 1.3204 - val_acc: 0.7778\n",
      "Epoch 42/100\n",
      "106/106 - 2s - loss: 0.1360 - acc: 0.9528 - val_loss: 1.3109 - val_acc: 0.7407\n",
      "Epoch 43/100\n",
      "106/106 - 2s - loss: 0.1284 - acc: 0.9623 - val_loss: 1.3236 - val_acc: 0.7778\n",
      "Epoch 44/100\n",
      "106/106 - 2s - loss: 0.1301 - acc: 0.9434 - val_loss: 1.3436 - val_acc: 0.7778\n",
      "Epoch 45/100\n",
      "106/106 - 2s - loss: 0.0986 - acc: 0.9623 - val_loss: 1.3525 - val_acc: 0.8148\n",
      "Epoch 46/100\n",
      "106/106 - 2s - loss: 0.1315 - acc: 0.9528 - val_loss: 1.3612 - val_acc: 0.7778\n",
      "Epoch 47/100\n",
      "106/106 - 2s - loss: 0.0997 - acc: 0.9434 - val_loss: 1.3658 - val_acc: 0.7407\n",
      "Epoch 48/100\n",
      "106/106 - 2s - loss: 0.1325 - acc: 0.9245 - val_loss: 1.4416 - val_acc: 0.7407\n",
      "Epoch 49/100\n",
      "106/106 - 2s - loss: 0.1331 - acc: 0.9434 - val_loss: 1.4221 - val_acc: 0.7778\n",
      "Epoch 50/100\n",
      "106/106 - 2s - loss: 0.0948 - acc: 0.9340 - val_loss: 0.9342 - val_acc: 0.8519\n",
      "Epoch 51/100\n",
      "106/106 - 2s - loss: 0.1066 - acc: 0.9434 - val_loss: 0.9559 - val_acc: 0.8519\n",
      "Epoch 52/100\n",
      "106/106 - 2s - loss: 0.1021 - acc: 0.9717 - val_loss: 0.9807 - val_acc: 0.8148\n",
      "Epoch 53/100\n",
      "106/106 - 2s - loss: 0.1396 - acc: 0.9151 - val_loss: 1.2693 - val_acc: 0.7778\n",
      "Epoch 54/100\n",
      "106/106 - 2s - loss: 0.1279 - acc: 0.9057 - val_loss: 1.3778 - val_acc: 0.8148\n",
      "Epoch 55/100\n",
      "106/106 - 2s - loss: 0.1071 - acc: 0.9623 - val_loss: 1.3906 - val_acc: 0.8148\n",
      "Epoch 56/100\n",
      "106/106 - 2s - loss: 0.0847 - acc: 0.9623 - val_loss: 1.3625 - val_acc: 0.8148\n",
      "Epoch 57/100\n",
      "106/106 - 2s - loss: 0.1098 - acc: 0.9528 - val_loss: 1.3467 - val_acc: 0.7778\n",
      "Epoch 58/100\n",
      "106/106 - 2s - loss: 0.1007 - acc: 0.9528 - val_loss: 1.3662 - val_acc: 0.7778\n",
      "Epoch 59/100\n",
      "106/106 - 2s - loss: 0.1189 - acc: 0.9151 - val_loss: 1.3697 - val_acc: 0.7778\n",
      "Epoch 60/100\n",
      "106/106 - 2s - loss: 0.1057 - acc: 0.9434 - val_loss: 1.4650 - val_acc: 0.8148\n",
      "Epoch 61/100\n",
      "106/106 - 4s - loss: 0.1524 - acc: 0.9340 - val_loss: 1.5826 - val_acc: 0.8148\n",
      "Epoch 62/100\n",
      "106/106 - 3s - loss: 0.1484 - acc: 0.9434 - val_loss: 1.5938 - val_acc: 0.8519\n",
      "Epoch 63/100\n",
      "106/106 - 3s - loss: 0.0997 - acc: 0.9623 - val_loss: 1.5223 - val_acc: 0.8148\n",
      "Epoch 64/100\n",
      "106/106 - 3s - loss: 0.0859 - acc: 0.9717 - val_loss: 1.4451 - val_acc: 0.8148\n",
      "Epoch 65/100\n",
      "106/106 - 3s - loss: 0.0979 - acc: 0.9528 - val_loss: 1.3676 - val_acc: 0.8148\n",
      "Epoch 66/100\n",
      "106/106 - 3s - loss: 0.0835 - acc: 0.9717 - val_loss: 1.3247 - val_acc: 0.8148\n",
      "Epoch 67/100\n",
      "106/106 - 2s - loss: 0.0950 - acc: 0.9623 - val_loss: 1.3101 - val_acc: 0.8148\n",
      "Epoch 68/100\n",
      "106/106 - 2s - loss: 0.1053 - acc: 0.9623 - val_loss: 1.3052 - val_acc: 0.8148\n",
      "Epoch 69/100\n",
      "106/106 - 2s - loss: 0.0731 - acc: 0.9623 - val_loss: 1.2593 - val_acc: 0.8148\n",
      "Epoch 70/100\n",
      "106/106 - 2s - loss: 0.0846 - acc: 0.9528 - val_loss: 1.2680 - val_acc: 0.7778\n",
      "Epoch 71/100\n",
      "106/106 - 2s - loss: 0.1190 - acc: 0.9528 - val_loss: 1.2541 - val_acc: 0.7778\n",
      "Epoch 72/100\n",
      "106/106 - 2s - loss: 0.0673 - acc: 0.9717 - val_loss: 1.2534 - val_acc: 0.7407\n",
      "Epoch 73/100\n",
      "106/106 - 2s - loss: 0.0877 - acc: 0.9434 - val_loss: 1.2620 - val_acc: 0.7407\n",
      "Epoch 74/100\n",
      "106/106 - 2s - loss: 0.0935 - acc: 0.9528 - val_loss: 1.2984 - val_acc: 0.7778\n",
      "Epoch 75/100\n",
      "106/106 - 2s - loss: 0.0699 - acc: 0.9623 - val_loss: 1.3494 - val_acc: 0.7407\n",
      "Epoch 76/100\n",
      "106/106 - 2s - loss: 0.0807 - acc: 0.9717 - val_loss: 1.4201 - val_acc: 0.8148\n",
      "Epoch 77/100\n",
      "106/106 - 2s - loss: 0.1314 - acc: 0.9434 - val_loss: 1.4664 - val_acc: 0.7407\n",
      "Epoch 78/100\n",
      "106/106 - 2s - loss: 0.1503 - acc: 0.9245 - val_loss: 1.4226 - val_acc: 0.7407\n",
      "Epoch 79/100\n",
      "106/106 - 2s - loss: 0.1745 - acc: 0.9057 - val_loss: 1.4855 - val_acc: 0.7037\n",
      "Epoch 80/100\n",
      "106/106 - 2s - loss: 0.2309 - acc: 0.8774 - val_loss: 1.3378 - val_acc: 0.7778\n",
      "Epoch 81/100\n",
      "106/106 - 2s - loss: 0.2328 - acc: 0.9245 - val_loss: 1.2794 - val_acc: 0.7407\n",
      "Epoch 82/100\n",
      "106/106 - 2s - loss: 0.1336 - acc: 0.9245 - val_loss: 1.2309 - val_acc: 0.8148\n",
      "Epoch 83/100\n",
      "106/106 - 2s - loss: 0.2385 - acc: 0.8962 - val_loss: 1.1379 - val_acc: 0.8148\n",
      "Epoch 84/100\n",
      "106/106 - 2s - loss: 0.2023 - acc: 0.8868 - val_loss: 1.0488 - val_acc: 0.7037\n",
      "Epoch 85/100\n",
      "106/106 - 2s - loss: 0.2474 - acc: 0.8585 - val_loss: 1.2084 - val_acc: 0.6296\n",
      "Epoch 86/100\n",
      "106/106 - 2s - loss: 0.1582 - acc: 0.9434 - val_loss: 1.3660 - val_acc: 0.6667\n",
      "Epoch 87/100\n",
      "106/106 - 2s - loss: 0.1527 - acc: 0.9151 - val_loss: 1.4822 - val_acc: 0.7037\n",
      "Epoch 88/100\n",
      "106/106 - 2s - loss: 0.1343 - acc: 0.9623 - val_loss: 1.5426 - val_acc: 0.7407\n",
      "Epoch 89/100\n",
      "106/106 - 2s - loss: 0.1361 - acc: 0.9340 - val_loss: 1.5899 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "106/106 - 2s - loss: 0.1194 - acc: 0.9434 - val_loss: 1.6039 - val_acc: 0.7778\n",
      "Epoch 91/100\n",
      "106/106 - 2s - loss: 0.1170 - acc: 0.9434 - val_loss: 1.6045 - val_acc: 0.7778\n",
      "Epoch 92/100\n",
      "106/106 - 2s - loss: 0.1075 - acc: 0.9717 - val_loss: 1.4824 - val_acc: 0.7778\n",
      "Epoch 93/100\n",
      "106/106 - 2s - loss: 0.1020 - acc: 0.9623 - val_loss: 1.3270 - val_acc: 0.7778\n",
      "Epoch 94/100\n",
      "106/106 - 2s - loss: 0.0995 - acc: 0.9528 - val_loss: 1.2561 - val_acc: 0.8148\n",
      "Epoch 95/100\n",
      "106/106 - 2s - loss: 0.1231 - acc: 0.9340 - val_loss: 1.2638 - val_acc: 0.8148\n",
      "Epoch 96/100\n",
      "106/106 - 2s - loss: 0.0835 - acc: 0.9717 - val_loss: 1.3043 - val_acc: 0.8148\n",
      "Epoch 97/100\n",
      "106/106 - 2s - loss: 0.1069 - acc: 0.9623 - val_loss: 1.5461 - val_acc: 0.7778\n",
      "Epoch 98/100\n",
      "106/106 - 2s - loss: 0.0685 - acc: 0.9717 - val_loss: 1.7136 - val_acc: 0.7778\n",
      "Epoch 99/100\n",
      "106/106 - 2s - loss: 0.0666 - acc: 0.9717 - val_loss: 1.7564 - val_acc: 0.7778\n",
      "Epoch 100/100\n",
      "106/106 - 3s - loss: 0.0847 - acc: 0.9623 - val_loss: 1.7018 - val_acc: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4266eb38>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X3_train_scaled, y3_train, validation_split=0.2, epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.4408 - acc: 0.9412\n"
     ]
    }
   ],
   "source": [
    "# Validate model using test data\n",
    "model_loss3, model_accuracy3 = model.evaluate(reshaped_X3_test_scaled, y3_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions3 = model.predict_classes(reshaped_X3_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "four_qtrs_out = pd.DataFrame({\"Predicted\":predictions3, \"Actual\":y3_test})\n",
    "# four_qtrs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name3 = f\"shuffled-4q-out-{int(dt.datetime.now())}\"\n",
    "model.save(f\"models/{name3}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X3_full = model.predict_classes(reshaped_X3_full)\n",
    "X3_full_results = pd.DataFrame({\"Predicted\":pred_X3_full, \"Actual\":y3})\n",
    "X3_full_results.to_csv(f\"resources/predictions/X3_full_shuffled_{int(dt.datetime.now())}.csv\")\n",
    "# X3_full_results.loc[X3_full_results[\"Actual\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X3-Y3 data (recession 4 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0]\n",
      " [ 2  3]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X3 model\n",
    "con_mat = confusion_matrix(y3_test, predictions3)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        29\n",
      "         1.0       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.97      0.80      0.86        34\n",
      "weighted avg       0.94      0.94      0.93        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y3_test, predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
